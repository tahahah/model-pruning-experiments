{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPSqBmQM-wyG"
      },
      "source": [
        "# Model Pruning Experiments\n",
        "\n",
        "This notebook demonstrates pruning experiments on:\n",
        "1. Vision Transformer (ViT)\n",
        "2. Deep Compression AutoEncoder (DC-AE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugpz1ix5-wyM",
        "outputId": "d904fc2d-979e-49e2-f5b2-829543559752"
      },
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/tahahah/model-pruning-experiments.git\n",
        "%cd model-pruning-experiments\n",
        "\n",
        "# Install dependencies\n",
        "!uv pip install --system -r requirements.txt"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 366.10 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 238.89 KiB/1.50 MiB\n",
            "\u001b[2monnxsim   \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 1.53 MiB/2.15 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 1.58 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.55 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 286.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.64 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.45 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.57 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.53 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 381.52 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.84 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.59 MiB/197.84 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 382.10 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 238.89 KiB/1.50 MiB\n",
            "\u001b[2monnxsim   \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 1.53 MiB/2.15 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 1.58 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.55 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 318.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.64 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.49 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.57 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.53 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 381.52 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.84 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.59 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.59 MiB/201.66 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 382.10 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 238.89 KiB/1.50 MiB\n",
            "\u001b[2monnxsim   \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 1.53 MiB/2.15 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 1.58 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.55 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 318.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.64 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.49 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.59 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.53 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 381.52 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.84 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.59 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.59 MiB/201.66 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 382.10 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 254.89 KiB/1.50 MiB\n",
            "\u001b[2monnxsim   \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 1.57 MiB/2.15 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 1.62 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.58 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 366.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.69 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.55 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.54 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.63 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.57 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 381.52 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.88 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.62 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.65 MiB/201.66 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 382.10 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 254.89 KiB/1.50 MiB\n",
            "\u001b[2monnxsim   \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 1.62 MiB/2.15 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 1.66 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.62 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 366.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.74 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.61 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.59 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.68 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.62 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 381.52 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.90 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.67 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.68 MiB/201.66 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 414.46 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 254.89 KiB/1.50 MiB\n",
            "\u001b[2monnxsim   \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 1.65 MiB/2.15 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 1.70 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.67 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 398.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.78 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.66 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.60 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.74 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.63 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 381.52 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.93 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.68 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.71 MiB/201.66 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 430.46 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 254.89 KiB/1.50 MiB\n",
            "\u001b[2monnxsim   \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 1.70 MiB/2.15 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 1.72 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.68 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 446.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.78 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.68 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.65 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.74 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.68 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 381.52 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.98 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.71 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.73 MiB/201.66 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 462.46 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 254.89 KiB/1.50 MiB\n",
            "\u001b[2monnxsim   \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 1.70 MiB/2.15 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 1.80 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.75 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 510.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.82 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.75 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.68 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.77 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.72 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 381.52 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.01 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.81 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.78 MiB/201.66 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 462.46 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 257.66 KiB/1.50 MiB\n",
            "\u001b[2monnxsim   \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 1.76 MiB/2.15 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 1.80 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.76 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 510.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.84 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.75 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.71 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.82 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.76 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 392.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.05 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.82 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.82 MiB/201.66 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 462.46 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 268.16 KiB/1.50 MiB\n",
            "\u001b[2monnxsim   \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 1.76 MiB/2.15 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 1.81 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.81 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 510.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.89 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.80 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.76 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.85 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 1.81 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 392.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.07 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.82 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.85 MiB/201.66 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 510.46 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 268.16 KiB/1.50 MiB\n",
            "\u001b[2monnxsim   \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 1.78 MiB/2.15 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 1.83 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.81 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 576.59 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.90 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.83 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.78 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.85 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 1.82 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 408.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.10 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.85 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.85 MiB/201.66 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 526.46 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 284.16 KiB/1.50 MiB\n",
            "\u001b[2monnxsim   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 1.82 MiB/2.15 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 1.86 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.85 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 590.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.92 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.83 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.81 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.90 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 1.84 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 424.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.13 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.90 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.90 MiB/201.66 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 526.46 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 284.16 KiB/1.50 MiB\n",
            "\u001b[2monnxsim   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 1.84 MiB/2.15 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1.91 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.89 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 590.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.96 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.85 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.85 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.91 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 1.87 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 424.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.17 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.95 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.93 MiB/201.66 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 537.51 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 300.16 KiB/1.50 MiB\n",
            "\u001b[2monnxsim   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 1.85 MiB/2.15 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1.91 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.89 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 590.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.96 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.88 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.85 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.93 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 1.88 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 456.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.17 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.95 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.95 MiB/201.66 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 551.89 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 300.16 KiB/1.50 MiB\n",
            "\u001b[2monnxsim   \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 1.88 MiB/2.15 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1.95 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.93 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 590.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.99 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.93 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.89 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.98 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 1.88 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 472.46 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.19 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.99 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.98 MiB/201.66 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 551.89 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 348.16 KiB/1.50 MiB\n",
            "\u001b[2monnxsim   \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 1.89 MiB/2.15 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1.99 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.98 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 590.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.03 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.93 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.93 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.98 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 1.92 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 520.46 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.23 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.99 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.01 MiB/201.66 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 551.89 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 364.16 KiB/1.50 MiB\n",
            "\u001b[2monnxsim   \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 1.92 MiB/2.15 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1.99 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.00 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 590.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.03 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.96 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.93 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 2.00 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 1.98 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 712.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.23 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.03 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.01 MiB/201.66 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 551.89 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 396.16 KiB/1.50 MiB\n",
            "\u001b[2monnxsim   \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 1.92 MiB/2.15 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 2.05 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.04 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 590.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.03 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.96 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.99 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 2.00 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 1.98 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 744.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.29 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.03 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.01 MiB/201.66 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 551.89 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 396.16 KiB/1.50 MiB\n",
            "\u001b[2monnxsim   \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 2.01 MiB/2.15 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 2.05 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.04 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 590.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.12 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.02 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.99 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 2.00 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 1.98 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 744.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.29 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.10 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.09 MiB/201.66 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 551.89 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 428.05 KiB/1.50 MiB\n",
            "\u001b[2monnxsim   \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 2.01 MiB/2.15 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 2.10 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.11 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 590.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.12 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.02 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.99 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 2.05 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.04 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 760.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.29 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.10 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.09 MiB/201.66 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 551.89 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 444.05 KiB/1.50 MiB\n",
            "\u001b[2monnxsim   \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 2.07 MiB/2.15 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 2.10 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.11 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 590.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.14 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.08 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.04 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 2.13 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.10 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 760.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.34 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.17 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.15 MiB/201.66 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 551.89 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 471.99 KiB/1.50 MiB\n",
            "\u001b[2monnxsim   \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 2.07 MiB/2.15 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 2.16 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.17 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 590.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.19 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.08 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.04 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 2.13 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.10 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 776.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.40 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.17 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.15 MiB/201.66 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 551.89 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 494.61 KiB/1.50 MiB\n",
            "\u001b[2monnxsim   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 2.12 MiB/2.15 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 2.16 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.17 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 590.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.25 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.13 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.04 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 2.13 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.10 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 792.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.40 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.17 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.23 MiB/201.66 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 551.89 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 524.16 KiB/1.50 MiB\n",
            "\u001b[2monnxsim   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 2.12 MiB/2.15 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 2.19 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.23 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 590.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.25 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.13 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.10 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 2.19 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.10 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 840.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.44 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.17 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.23 MiB/201.66 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 551.89 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 524.16 KiB/1.50 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 2.20 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.23 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 590.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.25 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.13 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.10 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 2.24 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.19 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 856.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.44 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.24 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.23 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.16 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 551.89 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 556.16 KiB/1.50 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 2.20 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.23 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 590.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.28 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.15 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.13 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 2.24 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.19 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 888.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.44 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.24 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.23 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.19 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 551.89 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 556.16 KiB/1.50 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 2.25 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.28 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 590.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.33 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.18 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.17 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 2.29 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.26 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 888.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.48 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.29 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.23 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.24 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 567.67 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 588.16 KiB/1.50 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 2.25 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.28 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 590.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.33 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.21 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.17 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 2.29 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.26 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 904.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.48 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.32 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.23 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.24 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 590.83 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 588.16 KiB/1.50 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 2.25 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.28 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 606.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.33 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.21 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.17 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 2.34 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.26 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 904.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.48 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.32 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.23 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.24 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 606.46 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 604.16 KiB/1.50 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 2.28 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.32 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 606.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.35 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.22 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.21 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 2.34 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.28 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 904.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.51 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.32 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.34 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.24 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 606.46 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 604.16 KiB/1.50 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 2.28 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.32 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 622.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.35 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.22 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.21 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 2.34 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.28 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 904.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.51 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.35 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.34 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.27 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 622.46 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 604.16 KiB/1.50 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 2.28 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.32 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 622.00 KiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.35 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.22 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.21 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 2.34 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.29 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 904.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.51 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.35 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.34 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.27 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 622.46 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 604.16 KiB/1.50 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 2.31 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.36 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.37 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.39 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.22 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.24 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.37 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.32 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 904.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.54 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.40 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.38 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.32 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 638.46 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 619.94 KiB/1.50 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 2.37 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.42 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.44 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.39 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.24 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.30 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.40 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.38 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 920.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.58 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.43 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.38 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.38 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 686.46 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 667.94 KiB/1.50 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 2.37 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.42 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.44 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.44 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.24 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.30 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.51 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.38 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 936.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.58 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.44 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.42 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.38 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 686.46 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 667.94 KiB/1.50 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 2.37 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.53 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.54 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.56 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.24 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.41 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.51 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.51 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 936.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.58 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.56 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.52 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.49 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 776.60 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 667.94 KiB/1.50 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 2.48 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.53 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.54 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.56 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.24 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.41 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.51 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.51 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 952.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.69 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.56 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.52 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.51 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 776.60 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 667.94 KiB/1.50 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 2.50 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.67 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.54 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.56 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.24 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.41 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.68 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.51 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 963.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.74 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.56 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.52 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.51 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 776.60 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 667.94 KiB/1.50 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 2.66 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.67 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.70 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.58 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.24 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.57 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.68 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.63 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 963.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.74 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.56 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.68 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.63 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/50)\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 862.46 KiB/905.57 KiB\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 667.94 KiB/1.50 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 2.66 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.67 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.70 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.71 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.24 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.57 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.68 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.63 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 979.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.69 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.68 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.63 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[23A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 667.94 KiB/1.50 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 2.66 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.67 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.87 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.71 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.24 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.57 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.68 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.63 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 979.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.96 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.69 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.68 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.63 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[22A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 698.06 KiB/1.50 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 2.66 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.67 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.87 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.71 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.24 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.57 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.68 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.63 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 979.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.96 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.69 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.68 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.63 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[22A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 698.06 KiB/1.50 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 2.66 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 2.86 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.87 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.71 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.25 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.57 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.68 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.80 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 995.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.96 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.69 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.85 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.63 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[22A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 698.06 KiB/1.50 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 2.66 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 2.86 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.87 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.88 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.25 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.71 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.84 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.80 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 995.56 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.96 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.85 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.85 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.79 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[22A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (31/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 714.06 KiB/1.50 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 2.83 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 2.86 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.90 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.88 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.27 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.74 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.84 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.80 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1011.01 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.99 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.85 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.85 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.79 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[22A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (31/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 714.06 KiB/1.50 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 2.98 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 2.86 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.90 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.88 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.27 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.74 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.85 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.80 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1011.01 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.99 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.99 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.85 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.79 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[22A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (31/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 714.06 KiB/1.50 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 2.98 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.00 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.04 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.88 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.27 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.83 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.98 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.98 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1011.01 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.13 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.99 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.98 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.91 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[22A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (31/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 730.06 KiB/1.50 MiB\n",
            "\u001b[2migraph    \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 2.98 MiB/3.00 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.00 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.04 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 3.00 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.27 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.97 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.98 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.98 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1011.01 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.13 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.99 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.98 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.91 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[22A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (31/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 730.06 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.00 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.04 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 3.00 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.27 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.97 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.98 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.98 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1011.01 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.13 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.99 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.98 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.91 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[21A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (32/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 730.06 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.14 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.17 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 3.00 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.27 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.97 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 3.12 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.98 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1011.01 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.24 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.14 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.98 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.04 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[21A      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (32/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 730.06 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.14 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.17 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.15 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.28 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.97 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 3.12 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 3.10 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1011.01 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.24 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.14 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.13 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.04 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[20A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (32/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 730.06 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.14 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.17 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.15 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.28 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.97 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 3.12 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 3.10 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1011.01 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.24 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.14 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.13 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.04 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[20A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (32/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 732.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.14 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.17 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.15 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.28 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.97 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 3.12 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 3.10 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1011.01 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.24 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.14 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.13 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.04 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[20A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (32/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 743.05 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.14 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.17 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.15 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.28 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.97 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 3.12 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 3.10 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1011.01 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.24 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.14 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.13 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.04 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[20A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (32/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 759.05 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.14 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.17 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.15 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.28 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.97 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 3.12 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 3.10 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1011.01 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.24 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.14 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.13 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.04 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[20A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (34/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 759.05 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.14 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.31 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.15 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.28 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 3.11 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 3.25 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 3.10 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1011.01 KiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.39 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.28 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.14 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.04 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[20A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (34/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 791.05 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 3.23 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.31 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.28 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.28 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 3.11 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 3.26 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 3.20 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.05 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.39 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.28 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.25 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.16 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[20A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (34/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 791.05 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 3.36 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 3.40 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.39 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.30 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 3.20 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 3.26 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 3.22 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.05 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.50 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.38 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.38 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.30 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[20A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (34/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 791.05 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 3.48 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 3.51 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.39 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.35 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 3.31 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 3.51 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 3.31 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.05 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.63 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.47 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.49 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.30 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[20A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (34/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 812.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 3.48 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 3.51 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 3.52 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.48 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 3.31 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 3.51 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 3.42 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.07 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.63 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.58 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.49 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.42 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[20A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (34/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 812.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 3.59 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 3.64 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 3.62 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.54 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 3.41 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 3.62 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 3.52 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.07 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.70 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.58 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.60 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.52 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[20A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (34/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 828.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 3.60 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 3.64 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 3.62 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.61 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 3.51 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 3.73 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 3.52 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.10 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.82 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.58 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.60 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.63 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[20A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (34/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 828.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 3.68 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 3.76 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 3.70 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.63 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 3.51 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 3.73 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 3.63 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.13 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.82 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.70 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.69 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.63 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[20A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (34/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 844.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 3.70 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 3.89 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 3.84 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.64 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 3.63 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 3.84 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 3.75 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.13 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.82 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.70 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.80 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.75 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[20A      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m efficientvit\u001b[2m @ git+https://github.com/mit-han-lab/efficientvit.git@b94ff\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (34/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 844.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 3.78 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 3.89 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 3.84 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.64 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 3.63 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 3.84 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 3.75 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.13 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.91 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.81 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.80 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.75 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[18A      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m segment-anything\u001b[2m @ git+https://github.com/facebookresearch/segment-anyth\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (34/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 844.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 3.78 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 3.89 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 3.84 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.64 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 3.63 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 3.84 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 3.75 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.14 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.91 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.81 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.80 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.75 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (34/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 844.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 3.90 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 3.89 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 3.84 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.64 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 3.72 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 3.93 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 3.75 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.42 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.03 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.89 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.80 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.75 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (34/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 844.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 3.90 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 4.00 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 3.95 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.64 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 3.72 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 3.96 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 3.85 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.74 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.03 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.89 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.91 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.86 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 844.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 4.00 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 4.14 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 3.95 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.64 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 3.84 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 3.96 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 3.98 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.33 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.05 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.02 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.91 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.97 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 844.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 4.06 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 4.22 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 4.14 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.64 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 3.91 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 4.16 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 4.03 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.52 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 4.23 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.08 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.06 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.14 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 844.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 4.22 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 4.39 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 4.31 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.66 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 4.05 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 4.31 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 4.14 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.79 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 4.42 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.23 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.22 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.22 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 844.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 4.38 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 4.51 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 4.47 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.66 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 4.17 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 4.44 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 4.30 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.82 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 4.56 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.39 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.37 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.34 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 844.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 4.49 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 4.69 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 4.61 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.66 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 4.30 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 4.66 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 4.45 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.82 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 4.72 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.53 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.52 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.56 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 844.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 4.66 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 4.87 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 4.73 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.66 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 4.45 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 4.77 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 4.62 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.87 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 4.84 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.67 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.62 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.66 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 844.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 4.83 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 4.98 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 4.92 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.66 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 4.63 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 4.89 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 4.78 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.90 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 5.01 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.81 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.79 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.82 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 844.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 4.93 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 5.12 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 5.05 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.66 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 4.75 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 5.04 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 4.90 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 3.32 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 5.13 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.95 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.91 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.93 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 844.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 5.02 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 5.12 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 5.12 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.66 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 4.75 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 5.14 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 4.90 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 4.17 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 5.13 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.04 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.97 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 844.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 5.13 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 5.31 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 5.24 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.66 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 4.94 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 5.25 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 5.07 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 4.42 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 5.31 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.15 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.10 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.12 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 860.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 5.30 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 5.48 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 5.31 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.66 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 5.01 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 5.45 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 5.31 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 4.65 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 5.51 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.24 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.29 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.29 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 860.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 5.39 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 5.58 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 5.46 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.66 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 5.21 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 5.51 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 5.35 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 4.73 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 5.59 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.45 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.37 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.38 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 860.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 5.57 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 5.76 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 5.64 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.66 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 5.42 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 5.51 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 5.51 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 4.93 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 5.80 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.59 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.57 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.57 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 860.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 5.76 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 5.76 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 5.81 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.66 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 5.42 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 5.71 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 5.51 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 4.93 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 5.99 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.59 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.77 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.57 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 860.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 5.76 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 5.97 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 5.86 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.66 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 5.62 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 5.92 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 5.73 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 5.12 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 5.99 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.78 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.77 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.84 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 860.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 5.97 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 6.15 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 6.05 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.66 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 5.62 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 6.11 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 5.91 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 5.12 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 6.15 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.99 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.95 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.92 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 860.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 5.97 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 6.15 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 6.05 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.66 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 5.84 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 6.12 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 5.91 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 5.32 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 6.21 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.99 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.95 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.92 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 860.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 5.97 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 6.15 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 6.07 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.66 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 6.03 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 6.30 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 5.91 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 5.32 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 6.21 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.99 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.95 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 6.11 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 860.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 6.16 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 6.36 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 6.26 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.66 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 6.03 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 6.30 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.08 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 5.32 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 6.41 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.99 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 6.15 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 6.11 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 908.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 6.37 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 6.36 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 6.26 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.89 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 6.24 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 6.30 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.10 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 5.52 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 6.41 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 6.21 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 6.33 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 6.13 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 908.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 6.38 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 6.56 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 6.45 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.89 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 6.24 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 6.49 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.26 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 5.70 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 6.60 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 6.37 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 6.33 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 6.33 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 924.05 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 6.39 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 6.76 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 6.46 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.89 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 6.45 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 6.51 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.33 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 5.89 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 6.83 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 6.44 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 6.54 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 6.36 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 924.05 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 6.59 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 6.76 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 6.64 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.89 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 6.46 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 6.69 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.54 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 5.89 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 6.83 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 6.63 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 6.54 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 6.52 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 940.05 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 6.60 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 6.79 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 6.65 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.90 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 6.48 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 6.70 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.54 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 5.91 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.04 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 6.65 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 6.54 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 6.74 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 940.05 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 6.76 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 6.97 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 6.81 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.92 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 6.66 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 6.88 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.68 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.08 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.04 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 6.80 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 6.73 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 6.74 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 940.05 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 6.95 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 7.01 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 6.86 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.92 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 6.90 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 6.90 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.89 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.11 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.25 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 6.99 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 6.93 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 6.94 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 956.05 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.15 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 7.20 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 7.03 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.92 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 6.91 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 7.09 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.95 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.31 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.27 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.05 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.08 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 6.97 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 956.05 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.17 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 7.40 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 7.19 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.92 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 7.10 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 7.28 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 7.09 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.48 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.47 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.24 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.13 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 7.17 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 972.05 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.18 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 7.43 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 7.24 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 4.80 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 7.12 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 7.30 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 7.14 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.50 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.47 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.24 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.17 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 7.19 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 972.05 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.18 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.76 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 7.24 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 4.80 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 7.12 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 7.66 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 7.31 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.59 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.73 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.24 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.17 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 7.21 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 972.05 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.46 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.76 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 7.50 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 4.80 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 7.39 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 7.66 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 7.31 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.59 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.73 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.43 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.44 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 7.57 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 988.05 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.46 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.87 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 7.50 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 5.08 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 7.39 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 7.66 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 7.67 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.62 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.73 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.43 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.86 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 7.57 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 988.05 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 7.82 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 8.11 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 7.84 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 5.39 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 7.47 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 8.00 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 7.67 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.62 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 8.09 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.88 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.86 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 7.82 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1004.05 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 7.82 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 8.42 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 8.10 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 5.39 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 7.76 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 8.00 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 7.67 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.64 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 8.09 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.88 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.86 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 8.17 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1004.05 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 8.09 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 8.42 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 8.10 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 5.68 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 8.06 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 8.29 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 8.09 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.64 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 8.09 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.88 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 8.20 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 8.17 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m tinyneuralnetwork\u001b[2m @ git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1004.05 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 8.09 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 8.42 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 8.10 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 5.68 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 8.06 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 8.31 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 8.09 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.64 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 8.36 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 8.12 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 8.20 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 8.17 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[14A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1004.05 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 8.09 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 8.42 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 8.10 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 5.70 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 8.06 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 8.31 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 8.09 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.64 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 8.36 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 8.12 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 8.20 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 8.17 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[14A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1004.05 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 8.31 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 8.64 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 8.42 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 5.86 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 8.06 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 8.48 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 8.28 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.64 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 8.64 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 8.40 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 8.37 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 8.17 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[14A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1004.05 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 8.50 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 8.81 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 8.59 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 6.07 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 8.45 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 8.68 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 8.53 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.64 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 8.79 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 8.61 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 8.72 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 8.58 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[14A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1004.05 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 8.75 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 9.04 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 8.86 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 6.32 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 8.68 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 8.92 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 8.77 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.66 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 9.07 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 8.84 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 8.84 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 8.81 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[14A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (35/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1020.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 9.06 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 9.15 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 9.13 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 6.35 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 8.95 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 9.01 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 9.01 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.66 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 9.18 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 8.97 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 9.13 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 8.93 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[14A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (36/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1020.16 KiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 9.25 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 9.40 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 9.37 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 6.35 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 8.98 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 9.25 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 9.26 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.66 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 9.40 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 9.21 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 9.20 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 9.14 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[14A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (36/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 1.01 MiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 9.27 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 9.61 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 9.39 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 6.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 9.16 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 9.46 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 9.29 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 7.10 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 9.57 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 9.38 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 9.38 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 9.32 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[14A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (36/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 1.01 MiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 9.50 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 9.86 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 9.56 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 6.40 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 9.41 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 9.73 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 9.45 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 7.41 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 9.79 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 9.56 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 9.59 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 9.48 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[14A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (36/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 1.03 MiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 9.71 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 10.03 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 9.78 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 6.40 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 9.56 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 9.90 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 9.68 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 7.60 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 9.93 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 9.77 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 9.79 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 9.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[14A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (36/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 1.04 MiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 9.95 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 10.29 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 9.87 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 6.41 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 9.81 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 10.17 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 9.74 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 7.72 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 10.10 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 9.85 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 9.87 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 9.92 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[14A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (36/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 1.06 MiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 9.95 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 10.29 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 10.06 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 7.12 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 9.84 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 10.17 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 9.88 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 8.12 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 10.40 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 10.19 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 10.09 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 9.92 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[14A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (36/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 1.06 MiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 10.37 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 10.61 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 10.45 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 7.12 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 10.10 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 10.44 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 10.24 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 8.20 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 10.68 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 10.47 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 10.35 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 10.22 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[14A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (36/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 1.07 MiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 10.64 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 11.04 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 10.75 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 7.12 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 10.44 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 10.84 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 10.65 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 8.30 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 10.88 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 10.69 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 10.66 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 10.58 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[14A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (36/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 1.07 MiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 10.94 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 11.30 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 11.01 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 7.12 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 10.77 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 11.12 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 10.91 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 8.38 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 11.17 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.03 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 10.90 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[14A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (36/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 1.09 MiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 11.08 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 11.44 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 11.13 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.23 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 10.88 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 11.27 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 11.08 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 8.73 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 11.31 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.17 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.16 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 11.05 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[14A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (36/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 1.09 MiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 11.24 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 11.59 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 11.29 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.23 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 11.02 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 11.39 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 11.20 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 9.10 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 11.47 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.30 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.30 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 11.19 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[14A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (36/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 1.10 MiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 11.24 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 11.59 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 11.43 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.23 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 11.16 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 11.52 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 11.20 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 10.14 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 11.58 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.30 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.30 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 11.19 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[14A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (36/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 1.10 MiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 11.45 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 11.82 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 11.54 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.27 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 11.27 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 11.65 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 11.42 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 10.41 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 11.72 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.55 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.42 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 11.44 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[14A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (36/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 1.10 MiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 11.59 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 11.93 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 11.67 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.37 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 11.38 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 11.75 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 11.53 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 10.64 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 11.86 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.66 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.64 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.57 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[14A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (36/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 1.10 MiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 11.81 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 12.16 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 11.85 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.37 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 11.61 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 11.87 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 11.74 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 10.70 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 12.07 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.89 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.85 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.77 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[14A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (36/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 1.10 MiB/1.50 MiB\n",
            "\u001b[2mruff      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 11.89 MiB/11.92 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 12.26 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 11.98 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 11.72 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 12.22 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 11.95 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 10.87 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 12.17 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.98 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.95 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[14A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (36/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 1.10 MiB/1.50 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 12.37 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 11.98 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 11.72 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 12.22 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 11.95 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 10.87 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 12.17 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.98 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.95 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[13A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (37/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 1.10 MiB/1.50 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 12.51 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 12.12 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.39 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 11.84 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 12.42 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 11.95 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 11.00 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 12.31 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 12.11 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 12.07 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.99 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[13A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (37/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 1.10 MiB/1.50 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 12.62 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 12.37 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.41 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 12.08 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 12.42 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 12.20 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 11.19 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 12.48 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 12.26 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 12.29 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 12.24 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[13A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (37/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 1.12 MiB/1.50 MiB\n",
            "\u001b[2monnxruntime\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 12.68 MiB/12.71 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 12.56 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.41 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 12.33 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 12.72 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 12.35 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 11.44 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 12.70 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 12.48 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 12.59 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 12.42 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[13A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (37/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 1.12 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 12.56 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.41 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 12.33 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 12.72 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 12.35 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 11.44 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 12.70 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 12.48 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 12.59 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 12.42 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[12A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (37/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 1.12 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 12.89 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.42 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 12.58 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 12.95 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 12.59 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 11.70 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 12.98 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 12.73 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 12.86 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 12.67 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[12A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (38/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 1.13 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 13.08 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.42 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 12.87 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 13.21 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 12.83 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 11.95 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 13.26 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 12.98 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 13.08 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 12.75 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[12A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (38/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 1.14 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 13.15 MiB/13.17 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.44 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 12.91 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 13.51 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 13.07 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 12.25 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 13.51 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 13.28 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 13.14 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 13.21 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[12A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (38/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 1.16 MiB/1.50 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.44 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 13.12 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 13.51 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 13.07 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 12.25 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 13.61 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 13.28 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 13.36 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 13.21 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (38/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 1.18 MiB/1.50 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.45 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 13.17 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 13.79 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 13.20 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 12.56 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 13.65 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 13.37 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 13.70 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 13.51 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (38/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 1.21 MiB/1.50 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.45 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 13.46 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 14.05 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 13.73 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 12.64 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 14.15 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 13.65 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 13.98 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 13.59 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (39/50)\n",
            "\u001b[2mjedi      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 1.21 MiB/1.50 MiB\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.45 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 13.99 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 14.16 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 13.78 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 13.03 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 14.26 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 13.98 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.02 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.07 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (39/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.47 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 13.99 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 14.36 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 13.93 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 13.03 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 14.49 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.15 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.27 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.07 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (39/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.47 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 14.04 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 14.65 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 14.22 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 13.18 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 14.55 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.46 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.52 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.36 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (39/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.47 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 14.40 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 14.95 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 14.58 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 13.78 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 15.10 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.83 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.88 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.74 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (39/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.47 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 14.93 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 15.28 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 14.91 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 14.18 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 15.43 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 15.20 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 15.17 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 15.02 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (40/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.48 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 15.27 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 15.65 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 15.25 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 14.48 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 15.69 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 15.46 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 15.52 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 15.35 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (40/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.48 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 15.59 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 15.93 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 15.50 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 14.73 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 16.03 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 15.77 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 15.83 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 15.69 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (40/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.48 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 15.98 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 16.30 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 15.99 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 15.11 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 16.42 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.18 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.23 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.03 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (40/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.48 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 16.22 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 16.56 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 16.14 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 15.41 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 16.74 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.45 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.53 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.03 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (40/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 16.46 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 16.62 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 16.44 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 15.71 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.06 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.51 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.59 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.59 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (40/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 16.62 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 16.94 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 16.44 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 15.79 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.06 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.79 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.87 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.59 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (40/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 16.77 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 17.24 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 16.78 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 16.00 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.25 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 17.09 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 17.21 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.95 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (40/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.18 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 17.62 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.15 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 16.05 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.72 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 17.45 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 17.60 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.29 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (40/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 17.74 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 18.06 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.73 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 16.06 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 18.18 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 17.95 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 18.07 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.78 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (40/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 18.00 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 18.41 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 18.02 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 16.09 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 18.51 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 18.24 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 18.32 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 18.09 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (40/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 18.33 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 18.62 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 18.27 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 16.11 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 18.71 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 18.57 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 18.54 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 18.27 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (40/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.52 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 18.63 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 18.90 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 18.67 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 16.14 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 18.99 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 18.88 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 18.99 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 18.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (40/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.52 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 19.04 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 19.28 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 19.02 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 16.14 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 19.37 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 19.25 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 19.35 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 19.10 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (40/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.56 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 19.27 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 19.52 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 19.27 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 16.29 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 19.63 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 19.52 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 19.57 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 19.36 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (40/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.57 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 19.66 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 19.89 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 19.67 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 16.31 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 19.96 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 19.89 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 20.02 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 19.78 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (40/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.57 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 19.95 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 20.22 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 19.95 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 16.31 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 20.29 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 20.19 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 20.26 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 20.00 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (40/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.57 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 20.53 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 20.28 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 16.32 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 20.58 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 20.53 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 20.57 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 20.31 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[9A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (40/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.57 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 20.69 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 20.47 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 16.34 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 20.81 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 20.68 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 20.72 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 20.45 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[9A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (40/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.57 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 21.05 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 20.79 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 16.34 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 21.20 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 21.09 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 21.14 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 20.84 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[9A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (40/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.60 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 21.51 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 21.25 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 16.35 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 21.62 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 21.48 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 21.53 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 21.35 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[9A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (40/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.60 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 21.93 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 21.67 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 16.38 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 21.97 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 21.90 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 22.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 21.79 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[9A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (41/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.60 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 22.37 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 22.09 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 16.38 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 22.51 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 22.38 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 22.40 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 22.23 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[9A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (41/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.64 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 22.75 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 22.53 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 16.40 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 22.93 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 22.85 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 22.90 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 22.55 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[9A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (41/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.65 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 23.24 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 23.00 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 16.43 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 23.44 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 23.27 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 23.43 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 23.11 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[9A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (41/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.65 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 23.31 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 16.45 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 23.72 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 23.55 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 23.71 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 23.41 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (41/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 7.65 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 23.65 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 16.46 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 24.05 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 23.88 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 24.02 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 23.75 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 7.67 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 24.24 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 16.54 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 24.69 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 24.48 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 24.61 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 24.28 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 7.68 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 24.92 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 16.63 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 25.22 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 25.12 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 25.28 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 24.88 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 7.68 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 25.61 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 16.67 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 25.78 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 25.73 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 25.91 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 25.60 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 7.70 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 26.16 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 16.78 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 26.38 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 26.27 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 26.39 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 26.04 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 7.78 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 26.77 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 16.90 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 27.00 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 26.85 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 26.94 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 26.58 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 7.78 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 27.18 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 16.93 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 27.40 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 27.30 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 27.38 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 27.05 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 7.78 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 27.33 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 17.26 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 27.57 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 27.49 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 27.54 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 27.21 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 7.78 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 27.70 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 17.41 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 27.79 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 27.71 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 27.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 27.44 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 7.78 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 27.92 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 17.45 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 28.20 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 28.06 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 28.12 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 27.80 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 7.78 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 28.10 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 18.26 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 28.39 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 28.26 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 28.31 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 27.95 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 7.78 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 28.24 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 19.45 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 28.85 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 28.62 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 28.42 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 28.05 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 7.79 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 28.68 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 19.83 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 28.96 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 28.78 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 28.83 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 28.49 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 7.90 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 28.87 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 20.16 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 29.37 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 29.18 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 29.06 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 28.79 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 7.90 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 29.38 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 20.47 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 29.63 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 29.55 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 29.45 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 29.23 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 7.90 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 29.85 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 20.76 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 29.78 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 29.93 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 29.90 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 29.76 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 7.90 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 30.25 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 21.19 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 30.54 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 30.10 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 30.03 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 29.86 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 7.90 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 30.75 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 21.19 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 30.65 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 30.55 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 30.50 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 30.58 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 7.90 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 31.06 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 21.20 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 31.25 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 31.32 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 31.06 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 30.96 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 7.90 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 31.65 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 21.22 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 31.80 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 31.74 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 31.56 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 31.50 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 7.92 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 31.87 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 21.22 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 32.22 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 32.14 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 31.88 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 31.92 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 7.92 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 32.42 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 21.23 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 32.66 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 32.66 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 32.40 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 32.39 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 7.93 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 32.81 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 21.23 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 33.12 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 33.10 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 32.84 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 32.76 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 7.95 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 33.13 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 21.24 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 33.66 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 33.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 33.41 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 33.18 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 7.96 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 33.54 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 21.26 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 33.98 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 33.98 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 33.84 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 33.70 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 7.96 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 34.01 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 21.29 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 34.49 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 34.38 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 34.19 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 34.00 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 7.96 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 34.51 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 21.34 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 35.05 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 34.94 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 34.81 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 34.61 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 7.96 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 34.86 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 21.37 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 35.33 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 35.25 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 35.15 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 34.93 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 8.10 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 35.33 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 21.38 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 35.85 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 35.71 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 35.63 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 35.45 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 8.13 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 35.70 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 21.86 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 36.19 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 36.17 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 35.98 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 35.78 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 8.16 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 36.12 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 22.02 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 36.56 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 36.37 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 36.35 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 36.24 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.28 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 36.45 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 22.15 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 36.92 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 36.74 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 36.71 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 36.60 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.28 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 36.79 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 22.33 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 37.27 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 37.09 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 37.03 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 36.93 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.29 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 37.12 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 22.93 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 37.71 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 37.47 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 37.42 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 37.39 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.29 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 37.79 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 22.98 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 38.29 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 38.08 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 38.04 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 37.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.31 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 38.43 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 23.14 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 38.88 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 38.67 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 38.65 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 38.35 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.31 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 38.91 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 23.40 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 39.39 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 39.28 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 39.19 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 38.92 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.45 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 39.55 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 23.76 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 40.02 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 39.84 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 39.83 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 39.57 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.45 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 40.00 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 23.86 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 40.51 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 40.40 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 40.36 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 40.11 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.46 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 40.33 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 24.50 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 40.88 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 40.77 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 40.73 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 40.51 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.47 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 40.34 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 26.13 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 41.00 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 40.77 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 40.73 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 40.51 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.47 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 40.64 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 26.39 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 41.21 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 41.30 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 41.28 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 40.96 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.47 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 41.09 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 27.06 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 41.85 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 41.72 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 41.68 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 41.35 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.47 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 41.74 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 27.56 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 42.52 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 42.14 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 42.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 41.90 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.47 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 42.23 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 27.93 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 42.77 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 42.70 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 42.67 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 42.25 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.47 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 42.71 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 28.12 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 43.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 42.98 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 42.85 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 42.72 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.47 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 43.11 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 28.12 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 43.61 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 43.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 43.28 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 43.04 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.47 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 43.36 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 28.14 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 44.07 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 43.93 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 43.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 43.43 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.49 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 43.83 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 28.16 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 44.51 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 44.20 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 44.01 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 44.00 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.49 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 44.40 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 28.20 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 45.00 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 44.76 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 44.60 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 44.49 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.49 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 44.83 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 28.25 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 45.39 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 45.31 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 45.02 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 44.88 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.49 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 45.36 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 28.28 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 45.79 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 45.70 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 45.55 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 45.31 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.49 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 45.78 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 28.57 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 46.28 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 46.17 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 46.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 45.82 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.49 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 46.24 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 28.90 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 46.63 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 46.58 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 46.39 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 46.24 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.51 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 46.70 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 29.21 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 47.06 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 47.01 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 46.83 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 46.66 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.51 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 47.09 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 29.28 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 47.61 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 47.52 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 47.29 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 47.07 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.51 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 47.42 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 29.46 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 47.89 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 47.80 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 47.59 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 47.38 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.51 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 47.79 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 29.53 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 48.31 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 48.20 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 47.97 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 47.83 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.51 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 48.14 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 29.99 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 48.65 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 48.55 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 48.31 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 48.18 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.51 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 48.46 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 30.78 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 48.98 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 48.89 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 48.67 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 48.53 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.53 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 48.85 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 31.06 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 49.35 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 49.22 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 49.15 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 48.92 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.53 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 49.24 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 31.62 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 49.79 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 49.75 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 49.45 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 49.36 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.53 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 49.85 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 31.62 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 50.35 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 50.24 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 50.04 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 49.95 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.53 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 50.45 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 31.65 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 50.80 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 50.81 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 50.51 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 50.52 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.53 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 51.00 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 31.74 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 51.41 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 51.36 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 51.11 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 51.08 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.54 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 51.51 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 31.75 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 51.92 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 51.77 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 51.69 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 51.57 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.54 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 52.00 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 31.75 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 52.64 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 52.39 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 52.31 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 52.18 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.54 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 52.68 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 31.75 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 53.15 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 52.98 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 52.89 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 52.69 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.54 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 53.24 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 31.77 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 53.71 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 53.63 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 53.46 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 53.29 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.56 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-curand-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 53.69 MiB/53.70 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 31.78 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 54.23 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 54.03 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 53.88 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 53.82 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.56 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 31.78 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 54.32 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 54.16 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 54.01 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 53.91 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.56 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 31.80 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 54.89 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 54.67 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 54.46 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 54.44 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 8.56 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 31.82 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 55.50 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 55.39 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 55.17 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 55.09 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (42/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.68 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 31.82 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 55.95 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 55.84 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 55.70 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 55.66 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.79 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 31.82 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.51 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.40 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.31 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.32 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.81 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 31.83 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 56.95 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.84 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.72 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.72 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.81 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 31.83 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 57.32 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.24 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.12 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 57.12 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.81 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 31.85 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 57.60 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.44 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.37 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 57.43 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.81 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 31.85 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 57.96 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.77 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.71 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 57.77 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.81 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 31.99 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 58.40 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 58.39 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 58.10 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 58.33 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.81 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 32.41 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 59.00 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 58.89 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 58.71 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 58.83 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.82 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 32.57 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 59.42 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 59.31 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 59.08 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 59.26 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.82 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 32.70 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 59.99 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 59.92 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 59.67 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 59.81 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.82 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 32.72 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 60.53 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 60.44 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 60.29 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 60.42 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.82 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 33.37 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 61.07 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 61.00 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 60.56 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 60.81 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.84 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 34.18 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 61.49 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 61.38 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 61.07 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 61.37 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.84 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 35.42 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 61.52 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 61.74 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 61.07 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 61.37 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.84 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 35.58 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 62.22 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 62.18 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 61.89 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 62.14 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.84 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 36.38 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 62.83 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 62.72 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 62.47 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 62.61 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.84 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 36.95 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 63.32 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 63.18 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 62.92 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 63.18 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.84 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 37.70 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 64.07 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 63.78 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 63.42 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 63.84 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.84 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 38.04 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 64.57 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 64.43 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 64.18 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 64.33 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.84 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 38.19 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 65.22 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 65.12 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 64.86 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 64.97 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.84 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 38.19 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 65.66 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 65.66 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 65.41 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 65.51 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.84 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 38.20 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 66.25 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 66.16 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 65.99 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 66.12 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.85 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 38.22 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 66.63 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 66.63 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 66.42 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 66.45 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.85 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 38.22 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 67.09 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 67.20 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 66.82 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 67.08 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.85 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 38.23 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 67.64 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 67.79 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 67.39 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 67.57 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.85 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 38.28 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 68.29 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 68.35 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 68.09 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 68.17 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.87 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 38.35 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 68.82 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 68.82 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 68.50 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 68.70 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.87 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 38.50 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 69.25 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 69.37 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 69.01 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 69.19 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.87 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 38.79 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 69.77 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 69.94 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 69.59 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 69.79 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.87 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 38.88 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 70.50 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 70.55 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 70.12 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 70.32 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.89 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 39.06 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 71.06 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 71.17 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 70.64 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 70.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.89 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 39.12 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 71.47 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 71.55 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 71.07 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 71.26 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.89 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 40.03 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 71.92 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 71.86 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 71.48 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 71.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.89 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 40.41 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 72.30 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 72.17 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 71.87 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 72.05 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.89 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 40.47 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 72.50 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 72.59 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 72.17 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 72.39 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.89 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 40.48 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 72.80 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 72.81 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 72.44 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 72.60 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.89 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 40.56 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 73.17 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 73.12 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 72.83 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 73.06 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.89 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 42.11 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 73.36 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 73.33 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 72.92 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 73.09 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.91 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 42.30 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 73.89 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 73.82 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 73.24 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 73.59 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.91 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 43.25 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 74.39 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 74.27 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 73.85 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 74.13 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.91 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 43.88 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 74.78 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 74.82 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 74.38 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 74.57 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.91 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 44.39 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 75.32 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 75.31 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 74.86 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 75.06 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.91 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 44.53 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 75.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 75.58 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 75.38 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 75.37 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.91 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 44.76 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 76.18 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 76.24 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 75.75 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 75.98 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.91 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 44.76 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 76.75 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 76.83 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 76.30 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 76.57 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.93 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 44.79 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 77.23 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 77.18 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 76.86 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 77.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.93 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 44.81 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 77.62 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 77.66 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 77.12 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 77.45 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.93 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 44.84 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 78.09 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 78.24 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 77.62 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 77.95 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.95 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 44.89 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 78.53 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 78.56 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 77.95 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 78.39 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.95 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 44.90 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 78.80 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 78.88 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 78.22 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 78.68 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.95 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 44.96 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 79.19 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 79.06 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 78.61 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 78.98 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.95 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 45.53 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 79.42 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 79.51 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 79.05 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 79.37 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 8.95 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 45.62 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 79.85 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 80.09 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 79.54 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 79.84 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 9.18 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 45.77 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 80.29 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 80.53 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 80.04 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 80.42 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.20 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 45.83 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 80.90 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 81.05 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 80.51 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 80.86 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.20 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 45.96 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 81.43 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 81.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 81.10 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 81.37 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.20 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 46.27 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 81.95 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 82.00 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 81.55 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 81.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.21 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 47.03 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 82.35 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 82.43 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 82.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 82.34 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.21 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 47.16 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 83.00 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 83.15 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 82.64 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 82.93 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.21 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 47.25 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 83.51 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 83.65 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 83.15 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 83.32 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.21 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 48.26 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 83.57 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 83.95 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 83.26 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 83.60 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.21 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 49.15 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 83.93 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 84.12 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 83.65 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 83.86 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.21 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 49.77 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 84.46 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 84.51 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 84.03 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 84.56 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.21 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 50.25 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 84.85 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 84.82 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 84.49 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 84.72 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.21 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 50.62 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 85.34 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 85.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 84.81 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 85.18 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.21 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 51.00 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 85.85 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 85.84 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 85.49 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 85.51 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.32 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 51.56 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 86.15 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 86.35 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 85.83 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 85.98 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.34 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 52.00 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 86.67 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 86.90 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 86.33 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 86.61 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.34 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 52.12 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 87.18 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 87.45 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 86.84 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 87.00 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.34 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 52.14 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 87.78 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 88.16 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 87.42 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 87.74 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.34 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 52.16 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 88.36 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 88.69 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 88.22 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 88.34 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.34 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 52.19 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 89.01 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 89.25 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 88.69 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 88.79 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.34 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 52.22 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 89.36 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 89.75 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 89.03 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 89.13 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.35 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 52.57 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 89.80 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 90.06 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 89.45 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 89.59 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.36 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 52.70 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 90.44 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 90.67 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 90.11 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 90.24 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.36 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 52.74 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 90.98 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 91.25 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 90.60 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 90.71 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.37 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 52.79 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 91.43 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 91.86 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 91.06 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 91.24 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.37 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 52.88 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 92.12 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 92.30 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 91.65 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 91.82 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.37 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 53.36 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 92.55 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 92.80 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 92.30 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 92.32 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.37 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 53.79 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 93.21 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 93.43 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 92.90 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 92.93 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.37 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 55.50 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 93.49 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 93.82 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 93.12 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 93.26 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.37 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 56.00 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 94.08 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 94.31 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 93.72 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 93.76 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.37 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 56.24 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 94.36 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 94.59 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 93.95 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 94.13 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.37 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 56.38 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 94.36 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 94.59 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 94.40 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 94.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.37 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 56.42 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 94.88 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 95.50 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 94.43 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 94.67 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.37 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 56.43 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 95.37 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 95.53 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 95.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 95.07 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.39 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 56.65 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 95.68 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 95.94 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 95.26 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 95.51 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.39 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 57.00 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 96.17 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 96.39 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 95.70 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 96.04 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.39 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 57.14 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 96.83 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 97.09 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 96.38 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 96.63 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.39 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 57.24 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 97.47 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 97.76 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 97.01 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 97.28 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.39 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 57.83 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 97.70 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 98.04 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 97.31 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 97.57 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.39 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 58.57 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 97.97 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 98.35 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 97.69 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 97.97 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.39 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 58.62 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 98.70 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 98.83 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 98.23 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 98.63 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.39 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 58.73 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 99.14 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 99.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 98.75 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 98.96 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.39 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 58.75 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 99.71 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 99.91 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 99.23 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 99.27 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.41 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 58.79 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 100.33 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 100.45 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 99.95 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 99.98 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.41 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 58.81 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 100.96 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 101.12 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 100.53 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 100.69 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.41 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 58.81 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 101.64 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 101.92 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 100.82 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 101.44 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.41 MiB/15.30 MiB\n",
            "\u001b[2mgradio    \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 58.92 MiB/59.32 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 102.06 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 102.36 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 101.84 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 101.92 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.41 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 102.06 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 102.36 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 101.84 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 101.92 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.41 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 102.57 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 103.02 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 102.42 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 102.53 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (43/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.41 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 103.25 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 103.64 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 102.97 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 103.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.41 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 103.86 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 104.25 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 103.68 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 103.76 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.41 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 104.51 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 104.97 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 104.33 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 104.10 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.41 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 105.10 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 105.86 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 105.18 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 104.70 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.41 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 106.13 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 106.67 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 105.72 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 105.70 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.41 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 106.97 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 107.30 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 106.65 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 106.44 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.42 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 107.50 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 107.93 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 107.47 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 107.37 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.42 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 108.11 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 108.59 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 108.04 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 107.70 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.42 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 109.20 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 109.60 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 108.34 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 108.29 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.42 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 110.00 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 110.28 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 109.60 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 109.48 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.42 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 110.58 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 111.11 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 110.16 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 109.98 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.42 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 111.60 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 111.98 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 111.23 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 110.95 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.42 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 112.44 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 112.78 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 111.97 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 111.76 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.42 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 113.14 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 113.32 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 112.98 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 112.74 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.42 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 113.92 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 114.30 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 113.60 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 113.58 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.42 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 114.81 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 115.17 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 114.43 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 114.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.42 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 115.42 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 115.78 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 115.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 114.56 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.42 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 115.73 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 116.22 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 115.63 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 115.09 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.42 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 116.21 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 116.70 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 116.11 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 115.66 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.42 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 116.59 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 117.39 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 116.47 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 116.36 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.42 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 117.12 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 117.93 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 116.85 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 116.91 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.42 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 118.06 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 118.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 117.48 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 117.14 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.42 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 118.31 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 119.19 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 118.07 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 117.72 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.42 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 118.95 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 119.77 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 118.92 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 118.64 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.42 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 119.91 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 120.52 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 119.71 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 119.40 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.42 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 120.67 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 121.26 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 120.50 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 119.93 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.43 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 121.70 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 121.81 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 121.01 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 120.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.43 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 121.98 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 122.93 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 121.87 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 121.24 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.43 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 123.19 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 122.25 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 121.94 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (44/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.43 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 123.72 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 122.61 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 122.40 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.43 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 123.91 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 122.95 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 122.90 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.43 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 125.04 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 123.65 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 123.48 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.43 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 125.88 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 125.09 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 124.68 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.43 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 126.68 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 125.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 125.47 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.43 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 127.62 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 126.79 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 126.44 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.43 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 128.42 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 128.42 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 127.34 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.43 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 129.74 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 129.06 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 127.92 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.44 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 130.30 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 129.06 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 128.78 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.44 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 130.74 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 130.10 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 129.86 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.45 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 132.16 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 130.93 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 130.78 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.45 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 132.85 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 131.78 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 131.55 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.45 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 133.71 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 132.68 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 132.87 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.47 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 134.43 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 133.48 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 133.64 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.47 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 135.56 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 134.72 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 134.37 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.47 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 136.68 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 135.58 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 135.09 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.47 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 137.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 136.98 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 136.34 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.47 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 138.53 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 137.81 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 137.31 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.47 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 139.34 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 138.84 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 138.48 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.47 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 140.35 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 139.59 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 139.33 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.48 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 141.63 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 140.65 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 140.35 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.48 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 142.72 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 141.94 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 141.39 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.48 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 143.48 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 142.71 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 142.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.48 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 144.01 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 142.99 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 142.52 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.48 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 144.31 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 143.84 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 143.30 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.48 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 145.08 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 144.37 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 143.75 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.48 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 145.78 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 144.84 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 144.11 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.48 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 146.18 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 145.65 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 145.14 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.48 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 147.25 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 145.95 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 145.59 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.48 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 148.04 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 146.66 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 146.31 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.48 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 148.66 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 147.48 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 147.41 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.48 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 149.57 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 148.59 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 148.08 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.48 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 150.31 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 149.52 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 148.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.48 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 151.01 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 150.50 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 149.59 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.48 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 152.21 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 151.16 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 150.70 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.48 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 153.07 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 151.93 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 151.46 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.49 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 153.96 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 153.15 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 152.19 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.49 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 154.71 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 154.09 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 153.53 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.49 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 155.48 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 154.78 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 154.27 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.49 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 156.28 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 155.45 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 155.34 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 157.38 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 156.64 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 156.02 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 158.27 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 157.38 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 157.11 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 159.81 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 158.43 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 157.94 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 160.62 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 159.86 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 159.02 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 161.74 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 160.82 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 159.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 162.52 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 161.67 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 160.92 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 163.62 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 162.89 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 161.67 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 164.35 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 163.63 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 162.75 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 165.09 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 164.26 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 164.01 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 165.96 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 165.82 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 164.80 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 166.47 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 165.82 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 164.80 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 166.71 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 166.43 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 165.42 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 167.49 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 166.61 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 165.67 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 168.13 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 167.11 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 166.33 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 168.91 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 167.84 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 167.12 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 170.09 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 168.94 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 167.99 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 171.21 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 169.65 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 168.90 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 171.88 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 170.97 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 169.44 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.52 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 172.71 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 171.62 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 170.76 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.52 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 173.43 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 172.46 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 171.54 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.52 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 173.63 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 172.68 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 172.49 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.52 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 174.64 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 173.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 172.63 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.52 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 175.53 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 174.57 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 173.96 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.52 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 176.25 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 175.53 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 174.81 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.52 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 177.15 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 176.31 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 175.63 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.52 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 177.95 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 177.33 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 176.69 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.52 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 179.19 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 177.95 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 177.46 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.52 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 179.97 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 178.89 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 178.34 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.52 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 180.68 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 179.56 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 179.25 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.52 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 182.05 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 180.57 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 180.03 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.53 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 182.93 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 181.81 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 181.28 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.53 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 184.12 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 182.88 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 182.74 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.53 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 185.49 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 184.86 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 184.10 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.53 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 187.06 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 185.87 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 185.02 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.53 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 187.79 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 186.54 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 185.95 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.53 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 188.71 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 187.87 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 187.20 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.53 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 189.30 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 188.15 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 187.40 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.53 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 190.08 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 188.86 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 188.20 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.53 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 191.52 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 190.67 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 189.73 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.55 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 192.92 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 192.03 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 191.52 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.55 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 194.05 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 192.93 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 192.61 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.55 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 195.16 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 194.33 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 193.41 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.55 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 196.64 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 195.53 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 194.87 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.55 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 197.38 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 196.11 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 195.58 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.55 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 196.11 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 195.58 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.55 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 197.65 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 197.50 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (45/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.55 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 199.44 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 198.98 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (46/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.55 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 200.96 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 200.11 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (46/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.55 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 200.96 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 200.54 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (46/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.55 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 201.59 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (46/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.56 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 202.03 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (46/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.56 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 204.42 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.56 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 207.23 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.56 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 209.47 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.57 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 211.09 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.57 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 212.33 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.57 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 214.13 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.57 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 216.31 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.57 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 218.67 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.57 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 220.21 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.57 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 221.78 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.57 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 224.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.57 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 226.25 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.57 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 227.78 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.57 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 229.36 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.57 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 231.62 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.57 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 233.34 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 9.57 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 235.33 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.21 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 236.85 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.21 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 238.36 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.21 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 239.84 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.21 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 241.33 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.24 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 242.79 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.24 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 243.68 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.24 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 244.55 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.24 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 246.84 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.36 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 247.41 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.36 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 248.66 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.36 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 250.30 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.36 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 251.95 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.36 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 253.22 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.36 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 255.01 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 256.71 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 257.87 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 259.79 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 261.28 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 262.14 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 263.64 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 264.98 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 266.73 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 268.59 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 270.12 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 271.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 272.87 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 274.59 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 276.12 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 278.11 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 279.83 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 282.06 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 283.86 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 285.17 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 286.75 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 288.23 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 289.95 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 291.18 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 293.20 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 294.06 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 295.17 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 295.61 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 296.23 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 297.07 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 298.58 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 299.43 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.39 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 300.59 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.39 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 301.57 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.39 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 301.83 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.39 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 304.16 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.41 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 304.87 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.41 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 306.13 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.41 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 307.50 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.44 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 310.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 10.45 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 311.06 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 10.77 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 313.81 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 10.82 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 316.64 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 10.96 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 318.34 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 10.96 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 321.27 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 10.96 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 322.95 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 10.98 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 325.70 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 10.98 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 327.97 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 10.99 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 330.53 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 10.99 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 331.81 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 10.99 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 334.73 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 10.99 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 337.57 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 10.99 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 338.92 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 11.03 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 340.57 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 11.70 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 340.58 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 11.70 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 341.58 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 11.81 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 342.33 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 11.95 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 342.33 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 11.95 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 342.33 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 12.00 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 342.33 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 12.02 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 342.33 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 12.05 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 342.33 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 12.28 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 343.11 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 12.32 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 343.11 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 12.35 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 343.11 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 12.36 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 343.11 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 12.36 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 343.11 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 12.38 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 343.11 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 12.51 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 343.11 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 12.54 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 343.11 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 12.54 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 343.11 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 12.67 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 343.51 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 12.67 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 343.98 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 12.70 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 343.98 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 12.70 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 343.98 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 12.73 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 343.98 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 12.99 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 343.98 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 13.07 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 343.98 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 13.08 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 343.98 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 13.09 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 343.98 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 13.35 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 343.98 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 13.35 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 344.50 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 13.35 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 344.51 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 13.35 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 345.05 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 13.41 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 345.05 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 13.43 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 345.05 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 13.43 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 345.05 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 13.46 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 345.05 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 13.47 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 345.05 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 13.49 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 345.05 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 13.49 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 345.05 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 13.50 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 345.44 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 13.52 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 346.12 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 13.55 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 346.12 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 13.55 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 346.12 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 13.57 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 346.12 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 13.58 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 346.12 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 13.58 MiB/15.30 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 346.12 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 13.58 MiB/15.30 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (47/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 13.58 MiB/15.30 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (48/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 13.67 MiB/15.30 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (48/50)\n",
            "\u001b[2monnx      \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 13.98 MiB/15.30 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (48/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (48/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (48/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (49/50)\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m50 packages\u001b[0m \u001b[2min 35.63s\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m11 packages\u001b[0m \u001b[2min 67ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m50 packages\u001b[0m \u001b[2min 552ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1maiofiles\u001b[0m\u001b[2m==23.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mantlr4-python3-runtime\u001b[0m\u001b[2m==4.9.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcoloredlogs\u001b[0m\u001b[2m==15.0.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==3.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdill\u001b[0m\u001b[2m==0.3.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mefficientvit\u001b[0m\u001b[2m==0.0.0 (from git+https://github.com/mit-han-lab/efficientvit.git@b94ff779828eea399c78f626b574da2d50ef2e49)\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfastapi\u001b[0m\u001b[2m==0.115.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mffmpy\u001b[0m\u001b[2m==0.5.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgradio\u001b[0m\u001b[2m==5.16.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgradio-client\u001b[0m\u001b[2m==1.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhumanfriendly\u001b[0m\u001b[2m==10.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1migraph\u001b[0m\u001b[2m==0.11.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mipdb\u001b[0m\u001b[2m==0.13.13\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjedi\u001b[0m\u001b[2m==0.19.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlightning-utilities\u001b[0m\u001b[2m==0.12.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlvis\u001b[0m\u001b[2m==0.5.3\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==2.1.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmultiprocess\u001b[0m\u001b[2m==0.70.16\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.5.3.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.4.5.8\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.3.0.75\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.1.0.70\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.2.3.61\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.2.1.3\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.6.82\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.5.147\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.6.3.83\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.6.1.9\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.1.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.3.1.170\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1momegaconf\u001b[0m\u001b[2m==2.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1monnx\u001b[0m\u001b[2m==1.17.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1monnxruntime\u001b[0m\u001b[2m==1.20.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1monnxsim\u001b[0m\u001b[2m==0.4.36\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydub\u001b[0m\u001b[2m==0.25.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpython-multipart\u001b[0m\u001b[2m==0.0.20\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mruamel-yaml\u001b[0m\u001b[2m==0.18.10\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mruamel-yaml-clib\u001b[0m\u001b[2m==0.2.12\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mruff\u001b[0m\u001b[2m==0.9.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msafehttpx\u001b[0m\u001b[2m==0.1.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msegment-anything\u001b[0m\u001b[2m==1.0 (from git+https://github.com/facebookresearch/segment-anything.git@dca509fe793f601edb92606367a655c15ac00fdf)\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msemantic-version\u001b[0m\u001b[2m==2.10.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mstarlette\u001b[0m\u001b[2m==0.45.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtexttable\u001b[0m\u001b[2m==1.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtinyneuralnetwork\u001b[0m\u001b[2m==0.1.0.20241219143703+fac2af5545167bbf0658a545ea68d14553d903b4 (from git+https://github.com/alibaba/TinyNeuralNetwork.git@fac2af5545167bbf0658a545ea68d14553d903b4)\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtomlkit\u001b[0m\u001b[2m==0.13.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorch-fidelity\u001b[0m\u001b[2m==0.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorch-pruning\u001b[0m\u001b[2m==1.5.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorchmetrics\u001b[0m\u001b[2m==1.6.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorchprofile\u001b[0m\u001b[2m==0.0.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1muvicorn\u001b[0m\u001b[2m==0.34.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mxxhash\u001b[0m\u001b[2m==3.5.0\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr9AYTje-wyb"
      },
      "source": [
        "## 1. Vision Transformer (ViT) Pruning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd model-pruning-experiments"
      ],
      "metadata": {
        "id": "l6g_gmSOm4Gj",
        "outputId": "a7c6f844-430d-45fb-f7c0-ca1e9719d326",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/model-pruning-experiments\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.abspath('..'))\n",
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from dcaecore.pacman_dataset_copy import PacmanDatasetProviderConfig, SimplePacmanDatasetProvider, StreamingPacmanDataset\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [15, 5]\n",
        "# First, let's verify we can get raw images directly from the dataset\n",
        "cfg = PacmanDatasetProviderConfig()\n",
        "raw_dataset = StreamingPacmanDataset(cfg, cfg.train_dataset, cfg.train_split)\n",
        "raw_iter = iter(raw_dataset)\n",
        "\n",
        "# Get a few raw samples and display them\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i in range(4):\n",
        "    plt.subplot(1, 4, i+1)\n",
        "    sample = next(raw_iter)\n",
        "    # Convert from [-1,1] to [0,1] range\n",
        "    img = (sample['data'] + 1) / 2\n",
        "    plt.imshow(img.permute(1, 2, 0))\n",
        "    plt.axis('off')\n",
        "plt.suptitle('Raw Dataset Images')\n",
        "plt.show()\n",
        "plt.savefig(\"my_chart.png\")"
      ],
      "metadata": {
        "id": "YMVzkK6JeUN1",
        "outputId": "2ab1dc5c-9c14-4d2b-dbaf-9a6c62c3fd73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610,
          "referenced_widgets": [
            "8837151c03ad4469a6b8818b80ea1ef9",
            "df55aae07979479b9522a54607080454",
            "ca1f1ca7ae594658bf4bdb3c883dd658",
            "49ce602dfc064005aa89e6c1e913db90",
            "de2dba06b609443c8c1516a9ca0643ec",
            "bda2af07a55c46d1afd6c22ee7fb8d67",
            "f961716071044e4f864e862e750aa61d",
            "5e8a804eb73a48a8b920f96cec89657d",
            "f64ae2be498f41938cef054ebcaaa391",
            "76599e70b2094050a9ba799eb985ce39",
            "921d7c11133342dd8bb3cb6634015cf6",
            "f52fc81fbe1f46778550108f44c7a17c",
            "c6c4599c8da3431183443487e356f362",
            "fb8ca64e2c54456a993734b94278f5aa",
            "a04d58edc22f4570b8c030b2697e0374",
            "d9acf1676726443bb9f758117090472e",
            "2021055773e44b7db7348413b3eb84b3",
            "36c168d1943e4bb3acd8421c2b86788e",
            "e949139f79c74e78822d009aefc7514c",
            "9d23cab0254047cb8279321310c686a8",
            "5a111af659eb47028e57a222d6ac9fd3",
            "20bc563ae3034b75afbe83094109e87c"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/339 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8837151c03ad4469a6b8818b80ea1ef9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/339 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f52fc81fbe1f46778550108f44c7a17c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_provider.train.dataset.dataset.features"
      ],
      "metadata": {
        "id": "KavFsz0ffmnj",
        "outputId": "d011a2a9-8050-4644-ee0c-3eecab4e1c23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'episode': Value(dtype='int64', id=None),\n",
              " 'frame_image': Image(mode=None, decode=True, id=None),\n",
              " 'action': Value(dtype='int64', id=None),\n",
              " 'next_frame_image': Image(mode=None, decode=True, id=None),\n",
              " 'done': Value(dtype='bool', id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show multiple batches to see streaming behavior\n",
        "print(\"Showing 3 consecutive batches from training dataset...\")\n",
        "for _ in range(3):\n",
        "    train_batch = next(iter(data_provider.train))\n",
        "    show_batch(train_batch, f'Training Batch {_+1}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "__eECLKHee6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twuJHYxZ-wyb"
      },
      "source": [
        "from vit_pruning_analysis import *\n",
        "\n",
        "# Run ViT pruning analysis\n",
        "main()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfQXndbB-wyc"
      },
      "source": [
        "## 2. DC-AE Pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xazu2nV4-wyc",
        "outputId": "68c192c2-f4cd-446c-ff7f-624c7390a740"
      },
      "source": [
        "!git stash && git pull"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved working directory and index state WIP on master: 74f3dfa fix: incorrect import utils\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python vae_pruning_analysis.py"
      ],
      "metadata": {
        "id": "vLT2n6GPhd2c",
        "outputId": "f1c3bbc0-8fd5-4f91-f530-10f5e983c53c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading DC-AE model...\n",
            "Using device: cuda\n",
            "\n",
            "Analyzing original model...\n",
            "\n",
            "Model Sparsity Analysis:\n",
            "Total Parameters: 323,105,472\n",
            "Non-zero Parameters: 323,105,472 (100.0%)\n",
            "Zero Parameters: 0 (0.0%)\n",
            "\n",
            "Top 10 Most Sparse Layers:\n",
            "                                                                      Layer     Size  NonZero  Sparsity(%)\n",
            "125                          decoder.project_out.op_list.2.conv.conv.weight    27648    27648          0.0\n",
            "0                                       encoder.project_in.conv.conv.weight     1728     1728          0.0\n",
            "1                         encoder.stages.1.op_list.0.main.conv1.conv.weight   589824   589824          0.0\n",
            "2                         encoder.stages.1.op_list.0.main.conv2.conv.weight   589824   589824          0.0\n",
            "3                         encoder.stages.1.op_list.1.main.conv1.conv.weight   589824   589824          0.0\n",
            "4                         encoder.stages.1.op_list.1.main.conv2.conv.weight   589824   589824          0.0\n",
            "110          decoder.stages.4.op_list.2.context_module.main.qkv.conv.weight  3145728  3145728          0.0\n",
            "111         decoder.stages.4.op_list.2.context_module.main.proj.conv.weight  1048576  1048576          0.0\n",
            "112  decoder.stages.4.op_list.2.local_module.main.inverted_conv.conv.weight  8388608  8388608          0.0\n",
            "113     decoder.stages.4.op_list.2.local_module.main.depth_conv.conv.weight    73728    73728          0.0\n",
            "\n",
            "Analyzing weight distributions at sparsity 0.0\n",
            "\n",
            "Model Sparsity Analysis:\n",
            "Total Parameters: 323,105,472\n",
            "Non-zero Parameters: 323,105,472 (100.0%)\n",
            "Zero Parameters: 0 (0.0%)\n",
            "\n",
            "Top 10 Most Sparse Layers:\n",
            "                                                                      Layer     Size  NonZero  Sparsity(%)\n",
            "125                          decoder.project_out.op_list.2.conv.conv.weight    27648    27648          0.0\n",
            "0                                       encoder.project_in.conv.conv.weight     1728     1728          0.0\n",
            "1                         encoder.stages.1.op_list.0.main.conv1.conv.weight   589824   589824          0.0\n",
            "2                         encoder.stages.1.op_list.0.main.conv2.conv.weight   589824   589824          0.0\n",
            "3                         encoder.stages.1.op_list.1.main.conv1.conv.weight   589824   589824          0.0\n",
            "4                         encoder.stages.1.op_list.1.main.conv2.conv.weight   589824   589824          0.0\n",
            "110          decoder.stages.4.op_list.2.context_module.main.qkv.conv.weight  3145728  3145728          0.0\n",
            "111         decoder.stages.4.op_list.2.context_module.main.proj.conv.weight  1048576  1048576          0.0\n",
            "112  decoder.stages.4.op_list.2.local_module.main.inverted_conv.conv.weight  8388608  8388608          0.0\n",
            "113     decoder.stages.4.op_list.2.local_module.main.depth_conv.conv.weight    73728    73728          0.0\n",
            "\n",
            "Analyzing weight distributions at sparsity 0.5\n",
            "\n",
            "Model Sparsity Analysis:\n",
            "Total Parameters: 323,105,472\n",
            "Non-zero Parameters: 161,552,732 (50.0%)\n",
            "Zero Parameters: 161,552,740 (50.0%)\n",
            "\n",
            "Top 10 Most Sparse Layers:\n",
            "                                                                      Layer     Size  NonZero  Sparsity(%)\n",
            "111         decoder.stages.4.op_list.2.context_module.main.proj.conv.weight  1048576   524287    50.000095\n",
            "101  decoder.stages.3.op_list.2.local_module.main.inverted_conv.conv.weight  2097152  1048575    50.000048\n",
            "51   encoder.stages.5.op_list.0.local_module.main.inverted_conv.conv.weight  8388608  4194303    50.000012\n",
            "117  decoder.stages.5.op_list.0.local_module.main.inverted_conv.conv.weight  8388608  4194303    50.000012\n",
            "89                        decoder.stages.2.op_list.9.main.conv1.conv.weight  2359296  1179648    50.000000\n",
            "88                        decoder.stages.2.op_list.8.main.conv2.conv.weight  2359296  1179648    50.000000\n",
            "87                        decoder.stages.2.op_list.8.main.conv1.conv.weight  2359296  1179648    50.000000\n",
            "86                        decoder.stages.2.op_list.7.main.conv2.conv.weight  2359296  1179648    50.000000\n",
            "85                        decoder.stages.2.op_list.7.main.conv1.conv.weight  2359296  1179648    50.000000\n",
            "90                        decoder.stages.2.op_list.9.main.conv2.conv.weight  2359296  1179648    50.000000\n",
            "\n",
            "Analyzing weight distributions at sparsity 0.7\n",
            "\n",
            "Model Sparsity Analysis:\n",
            "Total Parameters: 323,105,472\n",
            "Non-zero Parameters: 96,931,661 (30.0%)\n",
            "Zero Parameters: 226,173,811 (70.0%)\n",
            "\n",
            "Top 10 Most Sparse Layers:\n",
            "                                                                   Layer     Size  NonZero  Sparsity(%)\n",
            "97   decoder.stages.3.op_list.1.local_module.main.depth_conv.conv.weight    36864    11059    70.000543\n",
            "102  decoder.stages.3.op_list.2.local_module.main.depth_conv.conv.weight    36864    11059    70.000543\n",
            "30   encoder.stages.3.op_list.0.local_module.main.depth_conv.conv.weight    36864    11059    70.000543\n",
            "35   encoder.stages.3.op_list.1.local_module.main.depth_conv.conv.weight    36864    11059    70.000543\n",
            "100      decoder.stages.3.op_list.2.context_module.main.proj.conv.weight   262144    78643    70.000076\n",
            "28       encoder.stages.3.op_list.0.context_module.main.proj.conv.weight   262144    78643    70.000076\n",
            "33       encoder.stages.3.op_list.1.context_module.main.proj.conv.weight   262144    78643    70.000076\n",
            "95       decoder.stages.3.op_list.1.context_module.main.proj.conv.weight   262144    78643    70.000076\n",
            "65                     decoder.stages.1.op_list.2.main.conv2.conv.weight   589824   176947    70.000034\n",
            "13                     encoder.stages.2.op_list.1.main.conv2.conv.weight  2359296   707788    70.000034\n",
            "\n",
            "Analyzing weight distributions at sparsity 0.9\n",
            "\n",
            "Model Sparsity Analysis:\n",
            "Total Parameters: 323,105,472\n",
            "Non-zero Parameters: 32,310,601 (10.0%)\n",
            "Zero Parameters: 290,794,871 (90.0%)\n",
            "\n",
            "Top 10 Most Sparse Layers:\n",
            "                                                                      Layer      Size  NonZero  Sparsity(%)\n",
            "4                         encoder.stages.1.op_list.1.main.conv2.conv.weight    589824    58982    90.000068\n",
            "29   encoder.stages.3.op_list.0.local_module.main.inverted_conv.conv.weight   2097152   209715    90.000010\n",
            "104                        decoder.stages.4.op_list.0.main.conv.conv.weight  37748736  3774873    90.000002\n",
            "93                         decoder.stages.3.op_list.0.main.conv.conv.weight  18874368  1887437    89.999999\n",
            "107  decoder.stages.4.op_list.1.local_module.main.inverted_conv.conv.weight   8388608   838861    89.999998\n",
            "45   encoder.stages.4.op_list.1.local_module.main.inverted_conv.conv.weight   8388608   838861    89.999998\n",
            "40   encoder.stages.4.op_list.0.local_module.main.inverted_conv.conv.weight   8388608   838861    89.999998\n",
            "122  decoder.stages.5.op_list.1.local_module.main.inverted_conv.conv.weight   8388608   838861    89.999998\n",
            "112  decoder.stages.4.op_list.2.local_module.main.inverted_conv.conv.weight   8388608   838861    89.999998\n",
            "56   encoder.stages.5.op_list.1.local_module.main.inverted_conv.conv.weight   8388608   838861    89.999998\n",
            "\n",
            "Processing media_images_image_47095_fbef6038d915823a1016.png with sparsity 0.0\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.191279..1.1990021].\n",
            "Figure(1000x500)\n",
            "\n",
            "Model Sparsity Analysis:\n",
            "Total Parameters: 323,105,472\n",
            "Non-zero Parameters: 323,105,472 (100.0%)\n",
            "Zero Parameters: 0 (0.0%)\n",
            "\n",
            "Top 10 Most Sparse Layers:\n",
            "                                                                      Layer     Size  NonZero  Sparsity(%)\n",
            "125                          decoder.project_out.op_list.2.conv.conv.weight    27648    27648          0.0\n",
            "0                                       encoder.project_in.conv.conv.weight     1728     1728          0.0\n",
            "1                         encoder.stages.1.op_list.0.main.conv1.conv.weight   589824   589824          0.0\n",
            "2                         encoder.stages.1.op_list.0.main.conv2.conv.weight   589824   589824          0.0\n",
            "3                         encoder.stages.1.op_list.1.main.conv1.conv.weight   589824   589824          0.0\n",
            "4                         encoder.stages.1.op_list.1.main.conv2.conv.weight   589824   589824          0.0\n",
            "110          decoder.stages.4.op_list.2.context_module.main.qkv.conv.weight  3145728  3145728          0.0\n",
            "111         decoder.stages.4.op_list.2.context_module.main.proj.conv.weight  1048576  1048576          0.0\n",
            "112  decoder.stages.4.op_list.2.local_module.main.inverted_conv.conv.weight  8388608  8388608          0.0\n",
            "113     decoder.stages.4.op_list.2.local_module.main.depth_conv.conv.weight    73728    73728          0.0\n",
            "\n",
            "Processing media_images_image_47095_fbef6038d915823a1016.png with sparsity 0.5\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.107177734..1.1235747].\n",
            "Figure(1000x500)\n",
            "\n",
            "Model Sparsity Analysis:\n",
            "Total Parameters: 323,105,472\n",
            "Non-zero Parameters: 161,552,732 (50.0%)\n",
            "Zero Parameters: 161,552,740 (50.0%)\n",
            "\n",
            "Top 10 Most Sparse Layers:\n",
            "                                                                      Layer     Size  NonZero  Sparsity(%)\n",
            "111         decoder.stages.4.op_list.2.context_module.main.proj.conv.weight  1048576   524287    50.000095\n",
            "101  decoder.stages.3.op_list.2.local_module.main.inverted_conv.conv.weight  2097152  1048575    50.000048\n",
            "51   encoder.stages.5.op_list.0.local_module.main.inverted_conv.conv.weight  8388608  4194303    50.000012\n",
            "117  decoder.stages.5.op_list.0.local_module.main.inverted_conv.conv.weight  8388608  4194303    50.000012\n",
            "89                        decoder.stages.2.op_list.9.main.conv1.conv.weight  2359296  1179648    50.000000\n",
            "88                        decoder.stages.2.op_list.8.main.conv2.conv.weight  2359296  1179648    50.000000\n",
            "87                        decoder.stages.2.op_list.8.main.conv1.conv.weight  2359296  1179648    50.000000\n",
            "86                        decoder.stages.2.op_list.7.main.conv2.conv.weight  2359296  1179648    50.000000\n",
            "85                        decoder.stages.2.op_list.7.main.conv1.conv.weight  2359296  1179648    50.000000\n",
            "90                        decoder.stages.2.op_list.9.main.conv2.conv.weight  2359296  1179648    50.000000\n",
            "\n",
            "Processing media_images_image_47095_fbef6038d915823a1016.png with sparsity 0.7\n",
            "Figure(1000x500)\n",
            "\n",
            "Model Sparsity Analysis:\n",
            "Total Parameters: 323,105,472\n",
            "Non-zero Parameters: 96,931,661 (30.0%)\n",
            "Zero Parameters: 226,173,811 (70.0%)\n",
            "\n",
            "Top 10 Most Sparse Layers:\n",
            "                                                                   Layer     Size  NonZero  Sparsity(%)\n",
            "97   decoder.stages.3.op_list.1.local_module.main.depth_conv.conv.weight    36864    11059    70.000543\n",
            "102  decoder.stages.3.op_list.2.local_module.main.depth_conv.conv.weight    36864    11059    70.000543\n",
            "30   encoder.stages.3.op_list.0.local_module.main.depth_conv.conv.weight    36864    11059    70.000543\n",
            "35   encoder.stages.3.op_list.1.local_module.main.depth_conv.conv.weight    36864    11059    70.000543\n",
            "100      decoder.stages.3.op_list.2.context_module.main.proj.conv.weight   262144    78643    70.000076\n",
            "28       encoder.stages.3.op_list.0.context_module.main.proj.conv.weight   262144    78643    70.000076\n",
            "33       encoder.stages.3.op_list.1.context_module.main.proj.conv.weight   262144    78643    70.000076\n",
            "95       decoder.stages.3.op_list.1.context_module.main.proj.conv.weight   262144    78643    70.000076\n",
            "65                     decoder.stages.1.op_list.2.main.conv2.conv.weight   589824   176947    70.000034\n",
            "13                     encoder.stages.2.op_list.1.main.conv2.conv.weight  2359296   707788    70.000034\n",
            "\n",
            "Processing media_images_image_47095_fbef6038d915823a1016.png with sparsity 0.9\n",
            "Figure(1000x500)\n",
            "\n",
            "Model Sparsity Analysis:\n",
            "Total Parameters: 323,105,472\n",
            "Non-zero Parameters: 32,310,601 (10.0%)\n",
            "Zero Parameters: 290,794,871 (90.0%)\n",
            "\n",
            "Top 10 Most Sparse Layers:\n",
            "                                                                      Layer      Size  NonZero  Sparsity(%)\n",
            "4                         encoder.stages.1.op_list.1.main.conv2.conv.weight    589824    58982    90.000068\n",
            "29   encoder.stages.3.op_list.0.local_module.main.inverted_conv.conv.weight   2097152   209715    90.000010\n",
            "104                        decoder.stages.4.op_list.0.main.conv.conv.weight  37748736  3774873    90.000002\n",
            "93                         decoder.stages.3.op_list.0.main.conv.conv.weight  18874368  1887437    89.999999\n",
            "107  decoder.stages.4.op_list.1.local_module.main.inverted_conv.conv.weight   8388608   838861    89.999998\n",
            "45   encoder.stages.4.op_list.1.local_module.main.inverted_conv.conv.weight   8388608   838861    89.999998\n",
            "40   encoder.stages.4.op_list.0.local_module.main.inverted_conv.conv.weight   8388608   838861    89.999998\n",
            "122  decoder.stages.5.op_list.1.local_module.main.inverted_conv.conv.weight   8388608   838861    89.999998\n",
            "112  decoder.stages.4.op_list.2.local_module.main.inverted_conv.conv.weight   8388608   838861    89.999998\n",
            "56   encoder.stages.5.op_list.1.local_module.main.inverted_conv.conv.weight   8388608   838861    89.999998\n",
            "\n",
            "Processing media_images_image_2810940_edf08e2644ac8ed7a8d8.png with sparsity 0.0\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.1801014..1.2061813].\n",
            "Figure(1000x500)\n",
            "\n",
            "Model Sparsity Analysis:\n",
            "Total Parameters: 323,105,472\n",
            "Non-zero Parameters: 323,105,472 (100.0%)\n",
            "Zero Parameters: 0 (0.0%)\n",
            "\n",
            "Top 10 Most Sparse Layers:\n",
            "                                                                      Layer     Size  NonZero  Sparsity(%)\n",
            "125                          decoder.project_out.op_list.2.conv.conv.weight    27648    27648          0.0\n",
            "0                                       encoder.project_in.conv.conv.weight     1728     1728          0.0\n",
            "1                         encoder.stages.1.op_list.0.main.conv1.conv.weight   589824   589824          0.0\n",
            "2                         encoder.stages.1.op_list.0.main.conv2.conv.weight   589824   589824          0.0\n",
            "3                         encoder.stages.1.op_list.1.main.conv1.conv.weight   589824   589824          0.0\n",
            "4                         encoder.stages.1.op_list.1.main.conv2.conv.weight   589824   589824          0.0\n",
            "110          decoder.stages.4.op_list.2.context_module.main.qkv.conv.weight  3145728  3145728          0.0\n",
            "111         decoder.stages.4.op_list.2.context_module.main.proj.conv.weight  1048576  1048576          0.0\n",
            "112  decoder.stages.4.op_list.2.local_module.main.inverted_conv.conv.weight  8388608  8388608          0.0\n",
            "113     decoder.stages.4.op_list.2.local_module.main.depth_conv.conv.weight    73728    73728          0.0\n",
            "\n",
            "Processing media_images_image_2810940_edf08e2644ac8ed7a8d8.png with sparsity 0.5\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.1422686..1.1598299].\n",
            "Figure(1000x500)\n",
            "\n",
            "Model Sparsity Analysis:\n",
            "Total Parameters: 323,105,472\n",
            "Non-zero Parameters: 161,552,732 (50.0%)\n",
            "Zero Parameters: 161,552,740 (50.0%)\n",
            "\n",
            "Top 10 Most Sparse Layers:\n",
            "                                                                      Layer     Size  NonZero  Sparsity(%)\n",
            "111         decoder.stages.4.op_list.2.context_module.main.proj.conv.weight  1048576   524287    50.000095\n",
            "101  decoder.stages.3.op_list.2.local_module.main.inverted_conv.conv.weight  2097152  1048575    50.000048\n",
            "51   encoder.stages.5.op_list.0.local_module.main.inverted_conv.conv.weight  8388608  4194303    50.000012\n",
            "117  decoder.stages.5.op_list.0.local_module.main.inverted_conv.conv.weight  8388608  4194303    50.000012\n",
            "89                        decoder.stages.2.op_list.9.main.conv1.conv.weight  2359296  1179648    50.000000\n",
            "88                        decoder.stages.2.op_list.8.main.conv2.conv.weight  2359296  1179648    50.000000\n",
            "87                        decoder.stages.2.op_list.8.main.conv1.conv.weight  2359296  1179648    50.000000\n",
            "86                        decoder.stages.2.op_list.7.main.conv2.conv.weight  2359296  1179648    50.000000\n",
            "85                        decoder.stages.2.op_list.7.main.conv1.conv.weight  2359296  1179648    50.000000\n",
            "90                        decoder.stages.2.op_list.9.main.conv2.conv.weight  2359296  1179648    50.000000\n",
            "\n",
            "Processing media_images_image_2810940_edf08e2644ac8ed7a8d8.png with sparsity 0.7\n",
            "Figure(1000x500)\n",
            "\n",
            "Model Sparsity Analysis:\n",
            "Total Parameters: 323,105,472\n",
            "Non-zero Parameters: 96,931,661 (30.0%)\n",
            "Zero Parameters: 226,173,811 (70.0%)\n",
            "\n",
            "Top 10 Most Sparse Layers:\n",
            "                                                                   Layer     Size  NonZero  Sparsity(%)\n",
            "97   decoder.stages.3.op_list.1.local_module.main.depth_conv.conv.weight    36864    11059    70.000543\n",
            "102  decoder.stages.3.op_list.2.local_module.main.depth_conv.conv.weight    36864    11059    70.000543\n",
            "30   encoder.stages.3.op_list.0.local_module.main.depth_conv.conv.weight    36864    11059    70.000543\n",
            "35   encoder.stages.3.op_list.1.local_module.main.depth_conv.conv.weight    36864    11059    70.000543\n",
            "100      decoder.stages.3.op_list.2.context_module.main.proj.conv.weight   262144    78643    70.000076\n",
            "28       encoder.stages.3.op_list.0.context_module.main.proj.conv.weight   262144    78643    70.000076\n",
            "33       encoder.stages.3.op_list.1.context_module.main.proj.conv.weight   262144    78643    70.000076\n",
            "95       decoder.stages.3.op_list.1.context_module.main.proj.conv.weight   262144    78643    70.000076\n",
            "65                     decoder.stages.1.op_list.2.main.conv2.conv.weight   589824   176947    70.000034\n",
            "13                     encoder.stages.2.op_list.1.main.conv2.conv.weight  2359296   707788    70.000034\n",
            "\n",
            "Processing media_images_image_2810940_edf08e2644ac8ed7a8d8.png with sparsity 0.9\n",
            "Figure(1000x500)\n",
            "\n",
            "Model Sparsity Analysis:\n",
            "Total Parameters: 323,105,472\n",
            "Non-zero Parameters: 32,310,601 (10.0%)\n",
            "Zero Parameters: 290,794,871 (90.0%)\n",
            "\n",
            "Top 10 Most Sparse Layers:\n",
            "                                                                      Layer      Size  NonZero  Sparsity(%)\n",
            "4                         encoder.stages.1.op_list.1.main.conv2.conv.weight    589824    58982    90.000068\n",
            "29   encoder.stages.3.op_list.0.local_module.main.inverted_conv.conv.weight   2097152   209715    90.000010\n",
            "104                        decoder.stages.4.op_list.0.main.conv.conv.weight  37748736  3774873    90.000002\n",
            "93                         decoder.stages.3.op_list.0.main.conv.conv.weight  18874368  1887437    89.999999\n",
            "107  decoder.stages.4.op_list.1.local_module.main.inverted_conv.conv.weight   8388608   838861    89.999998\n",
            "45   encoder.stages.4.op_list.1.local_module.main.inverted_conv.conv.weight   8388608   838861    89.999998\n",
            "40   encoder.stages.4.op_list.0.local_module.main.inverted_conv.conv.weight   8388608   838861    89.999998\n",
            "122  decoder.stages.5.op_list.1.local_module.main.inverted_conv.conv.weight   8388608   838861    89.999998\n",
            "112  decoder.stages.4.op_list.2.local_module.main.inverted_conv.conv.weight   8388608   838861    89.999998\n",
            "56   encoder.stages.5.op_list.1.local_module.main.inverted_conv.conv.weight   8388608   838861    89.999998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Finetuning DC AE"
      ],
      "metadata": {
        "id": "MDi_POmHzfvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!uv pip install --system datasets\n",
        "!wandb login"
      ],
      "metadata": {
        "id": "fcG5NJ0Rz0Z4",
        "outputId": "28310238-623a-492e-9d38-7de0b58d84ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.11.11 environment at: /usr\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 115ms\u001b[0m\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtahaa\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"RANK\"] = \"0\"\n",
        "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
        "os.environ[\"LOCAL_RANK\"] = \"0\"\n",
        "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
        "os.environ[\"MASTER_PORT\"] = \"29500\""
      ],
      "metadata": {
        "id": "FQ_VuyoaR-C-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python dcaecore/train_dc_ae.py --config dcaecore/config.yaml --pretrained \"mit-han-lab/dc-ae-f32c32-in-1.0\" --output_dir dcaecore/outputs --gpu 0"
      ],
      "metadata": {
        "id": "R6PlDQl0ze-j",
        "outputId": "1e41a5e5-ebc2-4dad-bb6b-3e04721aef00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resolving data files: 100% 339/339 [00:00<00:00, 2778.46it/s]\n",
            "Resolving data files: 100% 339/339 [00:00<00:00, 33612.34it/s]\n",
            "Resolving data files: 100% 339/339 [00:00<00:00, 33535.44it/s]\n",
            "Resolving data files: 100% 339/339 [00:00<00:00, 418566.10it/s]\n",
            "2025-02-14 06:29:52,691 - dcae_training - INFO - Set random seed to 42\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtahaa\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/model-pruning-experiments/model-pruning-experiments/model-pruning-experiments/model-pruning-experiments/wandb/run-20250214_062952-rjirtx6f\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcherubic-valentine-20\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/tahaa/dcae-finetuning\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/tahaa/dcae-finetuning/runs/rjirtx6f\u001b[0m\n",
            "2025-02-14 06:29:54,100 - dcae_training - INFO - Initialized Weights & Biases logging\n",
            "2025-02-14 06:29:54,102 - dcae_training - INFO - Created data provider with batch size 1\n",
            "2025-02-14 06:29:54,102 - dcae_training - INFO - Loading pretrained model from mit-han-lab/dc-ae-f32c32-in-1.0\n",
            "2025-02-14 06:29:58,086 - dcae_training - INFO - Created training configuration\n",
            "/usr/local/lib/python3.11/dist-packages/torchmetrics/functional/image/lpips.py:323: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.load_state_dict(torch.load(model_path, map_location=\"cpu\"), strict=False)\n",
            "/usr/local/lib/python3.11/dist-packages/efficientvit/apps/trainer/base.py:223: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.enable_amp)\n",
            "2025-02-14 06:29:59,795 - dcae_training - INFO - Trainer setup complete\n",
            "2025-02-14 06:29:59,795 - dcae_training - INFO - Starting training...\n",
            "Training Epoch #0:  46% 46/100 [00:55<01:04,  1.20s/it, loss=0.0176, recon_loss=0.0154, perceptual_loss=0.0211, lr=1.03e-5]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/model-pruning-experiments/model-pruning-experiments/model-pruning-experiments/model-pruning-experiments/dcaecore/train_dc_ae.py\", line 253, in <module>\n",
            "    main()\n",
            "  File \"/content/model-pruning-experiments/model-pruning-experiments/model-pruning-experiments/model-pruning-experiments/dcaecore/train_dc_ae.py\", line 245, in main\n",
            "    trainer.train()\n",
            "  File \"/content/model-pruning-experiments/model-pruning-experiments/model-pruning-experiments/dcaecore/trainer.py\", line 281, in train\n",
            "    train_info = self.train_one_epoch(epoch)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/efficientvit/apps/trainer/base.py\", line 291, in train_one_epoch\n",
            "    train_info_dict = self._train_one_epoch(epoch)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/model-pruning-experiments/model-pruning-experiments/model-pruning-experiments/dcaecore/trainer.py\", line 223, in _train_one_epoch\n",
            "    feed_dict = self.before_step(feed_dict)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/efficientvit/apps/trainer/base.py\", line 262, in before_step\n",
            "    feed_dict[key] = feed_dict[key].cuda()\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "[rank0]: Traceback (most recent call last):\n",
            "[rank0]:   File \"/content/model-pruning-experiments/model-pruning-experiments/model-pruning-experiments/model-pruning-experiments/dcaecore/train_dc_ae.py\", line 253, in <module>\n",
            "[rank0]:     main()\n",
            "[rank0]:   File \"/content/model-pruning-experiments/model-pruning-experiments/model-pruning-experiments/model-pruning-experiments/dcaecore/train_dc_ae.py\", line 245, in main\n",
            "[rank0]:     trainer.train()\n",
            "[rank0]:   File \"/content/model-pruning-experiments/model-pruning-experiments/model-pruning-experiments/dcaecore/trainer.py\", line 281, in train\n",
            "[rank0]:     train_info = self.train_one_epoch(epoch)\n",
            "[rank0]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/efficientvit/apps/trainer/base.py\", line 291, in train_one_epoch\n",
            "[rank0]:     train_info_dict = self._train_one_epoch(epoch)\n",
            "[rank0]:                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/content/model-pruning-experiments/model-pruning-experiments/model-pruning-experiments/dcaecore/trainer.py\", line 223, in _train_one_epoch\n",
            "[rank0]:     feed_dict = self.before_step(feed_dict)\n",
            "[rank0]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/efficientvit/apps/trainer/base.py\", line 262, in before_step\n",
            "[rank0]:     feed_dict[key] = feed_dict[key].cuda()\n",
            "[rank0]:                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]: KeyboardInterrupt\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mcherubic-valentine-20\u001b[0m at: \u001b[34mhttps://wandb.ai/tahaa/dcae-finetuning/runs/rjirtx6f\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250214_062952-rjirtx6f/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git reset --hard && git pull\n"
      ],
      "metadata": {
        "id": "72A9bSwB3f7S",
        "outputId": "7a892978-acf6-4e68-8dd8-fb0026119176",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HEAD is now at 3ffb5b0 feat: better model naming\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (3/3), 315 bytes | 157.00 KiB/s, done.\n",
            "From https://github.com/tahahah/model-pruning-experiments\n",
            "   3ffb5b0..0d61fda  master     -> origin/master\n",
            "Updating 3ffb5b0..0d61fda\n",
            "Fast-forward\n",
            " iterative_prune_retrain.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Interactive Pruning"
      ],
      "metadata": {
        "id": "yblg_SGGrc_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python iterative_prune_retrain.py --config dcaecore/config.yaml --model_path \"mit-han-lab/dc-ae-f32c32-in-1.0\" --save_dir ./pruned_models --gpu 0"
      ],
      "metadata": {
        "id": "DC7LaTZmrfZi",
        "outputId": "67f75060-cecb-4791-82a5-13e9914ab7c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resolving data files: 100% 339/339 [00:00<00:00, 2712.68it/s]\n",
            "Resolving data files: 100% 339/339 [00:00<00:00, 64692.16it/s]\n",
            "Resolving data files: 100% 339/339 [00:00<00:00, 33097.51it/s]\n",
            "Resolving data files: 100% 339/339 [00:00<00:00, 421544.34it/s]\n",
            "2025-02-14 07:37:16,048 - dcae_training - INFO - \n",
            "=== Starting iteration 1 ===\n",
            "2025-02-14 07:37:16,048 - dcae_training - INFO - Current model statistics:\n",
            "\n",
            "Model Sparsity Analysis:\n",
            "Total Parameters: 323,105,472\n",
            "Non-zero Parameters: 323,105,472 (100.0%)\n",
            "Zero Parameters: 0 (0.0%)\n",
            "\n",
            "Top 10 Most Sparse Layers:\n",
            "                                                 Layer     Size  NonZero  Sparsity(%)\n",
            "0                  encoder.project_in.conv.conv.weight     1728     1728          0.0\n",
            "79   decoder.stages.2.op_list.4.main.conv1.conv.weight  2359296  2359296          0.0\n",
            "92  decoder.stages.2.op_list.10.main.conv2.conv.weight  2359296  2359296          0.0\n",
            "91  decoder.stages.2.op_list.10.main.conv1.conv.weight  2359296  2359296          0.0\n",
            "90   decoder.stages.2.op_list.9.main.conv2.conv.weight  2359296  2359296          0.0\n",
            "89   decoder.stages.2.op_list.9.main.conv1.conv.weight  2359296  2359296          0.0\n",
            "88   decoder.stages.2.op_list.8.main.conv2.conv.weight  2359296  2359296          0.0\n",
            "87   decoder.stages.2.op_list.8.main.conv1.conv.weight  2359296  2359296          0.0\n",
            "86   decoder.stages.2.op_list.7.main.conv2.conv.weight  2359296  2359296          0.0\n",
            "85   decoder.stages.2.op_list.7.main.conv1.conv.weight  2359296  2359296          0.0\n",
            "/usr/local/lib/python3.11/dist-packages/torchmetrics/functional/image/lpips.py:323: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.load_state_dict(torch.load(model_path, map_location=\"cpu\"), strict=False)\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.17326927..1.1916475].\n",
            "Saved reconstruction comparison to ./pruned_models/reconstructions_iter_1_before_pruning.png\n",
            "2025-02-14 07:37:20,149 - dcae_training - INFO - Pruning model by 50%...\n",
            "INFO:dcae_training:Pruning model by 50%...\n",
            "Model saved to ./pruned_models/model_pruned_iter_1.pth\n",
            "2025-02-14 07:37:32,964 - dcae_training - INFO - Pruned model statistics:\n",
            "INFO:dcae_training:Pruned model statistics:\n",
            "\n",
            "Model Sparsity Analysis:\n",
            "Total Parameters: 323,105,472\n",
            "Non-zero Parameters: 161,552,732 (50.0%)\n",
            "Zero Parameters: 161,552,740 (50.0%)\n",
            "\n",
            "Top 10 Most Sparse Layers:\n",
            "                                                                      Layer     Size  NonZero  Sparsity(%)\n",
            "111         decoder.stages.4.op_list.2.context_module.main.proj.conv.weight  1048576   524287    50.000095\n",
            "101  decoder.stages.3.op_list.2.local_module.main.inverted_conv.conv.weight  2097152  1048575    50.000048\n",
            "117  decoder.stages.5.op_list.0.local_module.main.inverted_conv.conv.weight  8388608  4194303    50.000012\n",
            "51   encoder.stages.5.op_list.0.local_module.main.inverted_conv.conv.weight  8388608  4194303    50.000012\n",
            "85                        decoder.stages.2.op_list.7.main.conv1.conv.weight  2359296  1179648    50.000000\n",
            "81                        decoder.stages.2.op_list.5.main.conv1.conv.weight  2359296  1179648    50.000000\n",
            "82                        decoder.stages.2.op_list.5.main.conv2.conv.weight  2359296  1179648    50.000000\n",
            "83                        decoder.stages.2.op_list.6.main.conv1.conv.weight  2359296  1179648    50.000000\n",
            "84                        decoder.stages.2.op_list.6.main.conv2.conv.weight  2359296  1179648    50.000000\n",
            "0                                       encoder.project_in.conv.conv.weight     1728      864    50.000000\n",
            "/usr/local/lib/python3.11/dist-packages/torchmetrics/functional/image/lpips.py:323: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.load_state_dict(torch.load(model_path, map_location=\"cpu\"), strict=False)\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.25230163..1.1985493].\n",
            "Saved reconstruction comparison to ./pruned_models/reconstructions_iter_1_after_pruning.png\n",
            "Do you want to retrain the pruned model? (yes/no): yes\n",
            "2025-02-14 07:37:38,354 - dcae_training - INFO - Starting retraining...\n",
            "INFO:dcae_training:Starting retraining...\n",
            "/usr/local/lib/python3.11/dist-packages/efficientvit/apps/trainer/base.py:223: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.enable_amp)\n",
            "Training Epoch #0: 100% 100/100 [01:56<00:00,  1.14s/it, loss=0.0227, recon_loss=0.0191, perceptual_loss=0.0364, lr=2.1e-5]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <dcaecore.pacman_dataset_copy.StreamingPacmanDataset object at 0x7ebdb5dc56d0> was reported to be 100(when accessing len(dataloader)), but 101 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.\n",
            "  warnings.warn(warn_msg)\n",
            "Training Epoch #0: 100% 100/100 [01:56<00:00,  1.16s/it, loss=0.0227, recon_loss=0.0191, perceptual_loss=0.0364, lr=2.1e-5]\n",
            "Validation Epoch #0: 100% 100/100 [00:36<00:00,  2.71it/s, loss=0.00483, recon_loss=0.00437, perceptual_loss=0.00458, psnr=30.3, ssim=nan, lpips=0.00458]\n",
            "Epoch 0: train_loss=0.0227, val_loss=0.0048, val_psnr=30.32, val_ssim=nan, val_lpips=0.0046\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.19082278..1.1870981].\n",
            "Saved reconstruction comparison to ./pruned_models/reconstructions_iter_1_after_retraining.png\n",
            "Do you want to continue with another round of pruning? (yes/no): yes\n",
            "2025-02-14 07:40:53,560 - dcae_training - INFO - \n",
            "=== Starting iteration 2 ===\n",
            "INFO:dcae_training:\n",
            "=== Starting iteration 2 ===\n",
            "2025-02-14 07:40:53,561 - dcae_training - INFO - Current model statistics:\n",
            "INFO:dcae_training:Current model statistics:\n",
            "\n",
            "Model Sparsity Analysis:\n",
            "Total Parameters: 323,105,472\n",
            "Non-zero Parameters: 323,064,931 (100.0%)\n",
            "Zero Parameters: 40,541 (0.0%)\n",
            "\n",
            "Top 10 Most Sparse Layers:\n",
            "                                                              Layer     Size  NonZero  Sparsity(%)\n",
            "27   encoder.stages.3.op_list.0.context_module.main.qkv.conv.weight   786432   779654     0.861867\n",
            "38   encoder.stages.4.op_list.0.context_module.main.qkv.conv.weight  3145728  3127829     0.568994\n",
            "49   encoder.stages.5.op_list.0.context_module.main.qkv.conv.weight  3145728  3138918     0.216484\n",
            "43   encoder.stages.4.op_list.1.context_module.main.qkv.conv.weight  3145728  3141680     0.128682\n",
            "120  decoder.stages.5.op_list.1.context_module.main.qkv.conv.weight  3145728  3141708     0.127792\n",
            "54   encoder.stages.5.op_list.1.context_module.main.qkv.conv.weight  3145728  3144746     0.031217\n",
            "32   encoder.stages.3.op_list.1.context_module.main.qkv.conv.weight   786432   786428     0.000509\n",
            "0                               encoder.project_in.conv.conv.weight     1728     1728     0.000000\n",
            "86                decoder.stages.2.op_list.7.main.conv2.conv.weight  2359296  2359296     0.000000\n",
            "83                decoder.stages.2.op_list.6.main.conv1.conv.weight  2359296  2359296     0.000000\n",
            "/usr/local/lib/python3.11/dist-packages/torchmetrics/functional/image/lpips.py:323: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.load_state_dict(torch.load(model_path, map_location=\"cpu\"), strict=False)\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.19082278..1.1870981].\n",
            "Saved reconstruction comparison to ./pruned_models/reconstructions_iter_2_before_pruning.png\n",
            "2025-02-14 07:40:54,765 - dcae_training - INFO - Pruning model by 50%...\n",
            "INFO:dcae_training:Pruning model by 50%...\n",
            "Model saved to ./pruned_models/model_pruned_iter_2.pth\n",
            "2025-02-14 07:41:32,171 - dcae_training - INFO - Pruned model statistics:\n",
            "INFO:dcae_training:Pruned model statistics:\n",
            "\n",
            "Model Sparsity Analysis:\n",
            "Total Parameters: 323,105,472\n",
            "Non-zero Parameters: 80,776,360 (25.0%)\n",
            "Zero Parameters: 242,329,112 (75.0%)\n",
            "\n",
            "Top 10 Most Sparse Layers:\n",
            "                                                                      Layer     Size  NonZero  Sparsity(%)\n",
            "65                        decoder.stages.1.op_list.2.main.conv2.conv.weight   589824   147455    75.000170\n",
            "121         decoder.stages.5.op_list.1.context_module.main.proj.conv.weight  1048576   262143    75.000095\n",
            "115          decoder.stages.5.op_list.0.context_module.main.qkv.conv.weight  3145728   786430    75.000064\n",
            "10                        encoder.stages.2.op_list.0.main.conv1.conv.weight  2359296   589823    75.000042\n",
            "13                        encoder.stages.2.op_list.1.main.conv2.conv.weight  2359296   589823    75.000042\n",
            "112  decoder.stages.4.op_list.2.local_module.main.inverted_conv.conv.weight  8388608  2097151    75.000012\n",
            "56   encoder.stages.5.op_list.1.local_module.main.inverted_conv.conv.weight  8388608  2097151    75.000012\n",
            "82                        decoder.stages.2.op_list.5.main.conv2.conv.weight  2359296   589824    75.000000\n",
            "83                        decoder.stages.2.op_list.6.main.conv1.conv.weight  2359296   589824    75.000000\n",
            "84                        decoder.stages.2.op_list.6.main.conv2.conv.weight  2359296   589824    75.000000\n",
            "/usr/local/lib/python3.11/dist-packages/torchmetrics/functional/image/lpips.py:323: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.load_state_dict(torch.load(model_path, map_location=\"cpu\"), strict=False)\n",
            "Saved reconstruction comparison to ./pruned_models/reconstructions_iter_2_after_pruning.png\n",
            "Do you want to retrain the pruned model? (yes/no): yes\n",
            "2025-02-14 07:42:11,344 - dcae_training - INFO - Starting retraining...\n",
            "INFO:dcae_training:Starting retraining...\n",
            "/usr/local/lib/python3.11/dist-packages/efficientvit/apps/trainer/base.py:223: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.enable_amp)\n",
            "Training Epoch #0: 100% 100/100 [01:56<00:00,  1.15s/it, loss=0.107, recon_loss=0.0966, perceptual_loss=0.108, lr=2.1e-5]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <dcaecore.pacman_dataset_copy.StreamingPacmanDataset object at 0x7ebdb5dc56d0> was reported to be 100(when accessing len(dataloader)), but 101 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.\n",
            "  warnings.warn(warn_msg)\n",
            "Training Epoch #0: 100% 100/100 [01:56<00:00,  1.17s/it, loss=0.107, recon_loss=0.0966, perceptual_loss=0.108, lr=2.1e-5]\n",
            "Validation Epoch #0: 100% 100/100 [00:36<00:00,  2.72it/s, loss=0.0095, recon_loss=0.00827, perceptual_loss=0.0123, psnr=27.2, ssim=nan, lpips=0.0123]\n",
            "Epoch 0: train_loss=0.1074, val_loss=0.0095, val_psnr=27.20, val_ssim=nan, val_lpips=0.0123\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.24110436..1.2249397].\n",
            "Saved reconstruction comparison to ./pruned_models/reconstructions_iter_2_after_retraining.png\n",
            "Do you want to continue with another round of pruning? (yes/no): yes\n",
            "2025-02-14 07:45:41,670 - dcae_training - INFO - \n",
            "=== Starting iteration 3 ===\n",
            "INFO:dcae_training:\n",
            "=== Starting iteration 3 ===\n",
            "2025-02-14 07:45:41,671 - dcae_training - INFO - Current model statistics:\n",
            "INFO:dcae_training:Current model statistics:\n",
            "\n",
            "Model Sparsity Analysis:\n",
            "Total Parameters: 323,105,472\n",
            "Non-zero Parameters: 322,969,383 (100.0%)\n",
            "Zero Parameters: 136,089 (0.0%)\n",
            "\n",
            "Top 10 Most Sparse Layers:\n",
            "                                                              Layer     Size  NonZero  Sparsity(%)\n",
            "120  decoder.stages.5.op_list.1.context_module.main.qkv.conv.weight  3145728  3088804     1.809565\n",
            "49   encoder.stages.5.op_list.0.context_module.main.qkv.conv.weight  3145728  3098305     1.507537\n",
            "38   encoder.stages.4.op_list.0.context_module.main.qkv.conv.weight  3145728  3135211     0.334326\n",
            "43   encoder.stages.4.op_list.1.context_module.main.qkv.conv.weight  3145728  3138114     0.242043\n",
            "27   encoder.stages.3.op_list.0.context_module.main.qkv.conv.weight   786432   784875     0.197983\n",
            "54   encoder.stages.5.op_list.1.context_module.main.qkv.conv.weight  3145728  3141137     0.145944\n",
            "99   decoder.stages.3.op_list.2.context_module.main.qkv.conv.weight   786432   785408     0.130208\n",
            "77                decoder.stages.2.op_list.3.main.conv1.conv.weight  2359296  2356365     0.124232\n",
            "78                decoder.stages.2.op_list.3.main.conv2.conv.weight  2359296  2356447     0.120756\n",
            "32   encoder.stages.3.op_list.1.context_module.main.qkv.conv.weight   786432   785773     0.083796\n",
            "/usr/local/lib/python3.11/dist-packages/torchmetrics/functional/image/lpips.py:323: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.load_state_dict(torch.load(model_path, map_location=\"cpu\"), strict=False)\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.24110436..1.2249397].\n",
            "Saved reconstruction comparison to ./pruned_models/reconstructions_iter_3_before_pruning.png\n",
            "2025-02-14 07:45:42,821 - dcae_training - INFO - Pruning model by 50%...\n",
            "INFO:dcae_training:Pruning model by 50%...\n",
            "Model saved to ./pruned_models/model_pruned_iter_3.pth\n",
            "2025-02-14 07:46:13,123 - dcae_training - INFO - Pruned model statistics:\n",
            "INFO:dcae_training:Pruned model statistics:\n",
            "\n",
            "Model Sparsity Analysis:\n",
            "Total Parameters: 323,105,472\n",
            "Non-zero Parameters: 40,388,178 (12.5%)\n",
            "Zero Parameters: 282,717,294 (87.5%)\n",
            "\n",
            "Top 10 Most Sparse Layers:\n",
            "                                                                      Layer      Size  NonZero  Sparsity(%)\n",
            "42      encoder.stages.4.op_list.0.local_module.main.point_conv.conv.weight   4194304   524287    87.500024\n",
            "107  decoder.stages.4.op_list.1.local_module.main.inverted_conv.conv.weight   8388608  1048575    87.500012\n",
            "104                        decoder.stages.4.op_list.0.main.conv.conv.weight  37748736  4718589    87.500008\n",
            "93                         decoder.stages.3.op_list.0.main.conv.conv.weight  18874368  2359295    87.500005\n",
            "0                                       encoder.project_in.conv.conv.weight      1728      216    87.500000\n",
            "91                       decoder.stages.2.op_list.10.main.conv1.conv.weight   2359296   294912    87.500000\n",
            "90                        decoder.stages.2.op_list.9.main.conv2.conv.weight   2359296   294912    87.500000\n",
            "89                        decoder.stages.2.op_list.9.main.conv1.conv.weight   2359296   294912    87.500000\n",
            "88                        decoder.stages.2.op_list.8.main.conv2.conv.weight   2359296   294912    87.500000\n",
            "87                        decoder.stages.2.op_list.8.main.conv1.conv.weight   2359296   294912    87.500000\n",
            "/usr/local/lib/python3.11/dist-packages/torchmetrics/functional/image/lpips.py:323: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.load_state_dict(torch.load(model_path, map_location=\"cpu\"), strict=False)\n",
            "Saved reconstruction comparison to ./pruned_models/reconstructions_iter_3_after_pruning.png\n",
            "Do you want to retrain the pruned model? (yes/no): yes\n",
            "2025-02-14 07:47:35,550 - dcae_training - INFO - Starting retraining...\n",
            "INFO:dcae_training:Starting retraining...\n",
            "/usr/local/lib/python3.11/dist-packages/efficientvit/apps/trainer/base.py:223: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.enable_amp)\n",
            "Training Epoch #0: 100% 100/100 [01:56<00:00,  1.15s/it, loss=0.286, recon_loss=0.256, perceptual_loss=0.3, lr=2.1e-5]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <dcaecore.pacman_dataset_copy.StreamingPacmanDataset object at 0x7ebdb5dc56d0> was reported to be 100(when accessing len(dataloader)), but 101 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.\n",
            "  warnings.warn(warn_msg)\n",
            "Training Epoch #0: 100% 100/100 [01:56<00:00,  1.17s/it, loss=0.286, recon_loss=0.256, perceptual_loss=0.3, lr=2.1e-5]\n",
            "Validation Epoch #0: 100% 100/100 [00:36<00:00,  2.75it/s, loss=0.0327, recon_loss=0.0275, perceptual_loss=0.0514, psnr=22.1, ssim=nan, lpips=0.0514]\n",
            "Epoch 0: train_loss=0.2865, val_loss=0.0327, val_psnr=22.15, val_ssim=nan, val_lpips=0.0514\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.12297183..1.3182461].\n",
            "Saved reconstruction comparison to ./pruned_models/reconstructions_iter_3_after_retraining.png\n",
            "Do you want to continue with another round of pruning? (yes/no): "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ./pruned_models\n",
        "!mkdir ./pruned_models"
      ],
      "metadata": {
        "id": "jjET5KRFyd6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Gradio UI"
      ],
      "metadata": {
        "id": "B1fXGTymQYSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git reset --hard && git pull"
      ],
      "metadata": {
        "id": "RbreM-WzRFEL",
        "outputId": "86e5e286-1718-4f47-89d8-c95213adeb93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HEAD is now at cb85514 forgot to add self\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (3/3), 522 bytes | 104.00 KiB/s, done.\n",
            "From https://github.com/tahahah/model-pruning-experiments\n",
            "   cb85514..0d9fcd5  master     -> origin/master\n",
            "Updating cb85514..0d9fcd5\n",
            "Fast-forward\n",
            " vae_pruning_analysis.py | 11 \u001b[32m+++++++++\u001b[m\u001b[31m--\u001b[m\n",
            " 1 file changed, 9 insertions(+), 2 deletions(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python app.py"
      ],
      "metadata": {
        "id": "-f5h9aMgQu0Z",
        "outputId": "0c56fb0f-2069-408e-cd15-ca401b89ac2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchmetrics/functional/image/lpips.py:323: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.load_state_dict(torch.load(model_path, map_location=\"cpu\"), strict=False)\n",
            "2025-02-14 15:38:46,710 - httpx - INFO - HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
            "* Running on local URL:  http://0.0.0.0:7860\n",
            "2025-02-14 15:38:46,802 - httpx - INFO - HTTP Request: GET http://localhost:7860/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
            "2025-02-14 15:38:46,822 - httpx - INFO - HTTP Request: HEAD http://localhost:7860/ \"HTTP/1.1 200 OK\"\n",
            "2025-02-14 15:38:47,029 - httpx - INFO - HTTP Request: GET https://api.gradio.app/v3/tunnel-request \"HTTP/1.1 200 OK\"\n",
            "* Running on public URL: https://b1befb49013d2cd33e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "2025-02-14 15:39:28,448 - model_manager - INFO - Loading initial model from mit-han-lab/dc-ae-f32c32-in-1.0\n",
            "2025-02-14 15:39:28,448 - model_manager - INFO - Initializing model...\n",
            "2025-02-14 15:39:32,492 - model_manager - INFO - Moving model to device: cuda:0\n",
            "2025-02-14 15:39:32,851 - model_manager - INFO - Creating equipped model copy...\n",
            "2025-02-14 15:39:32,919 - model_manager - INFO - Computing metrics and saving visualizations...\n",
            "2025-02-14 15:39:32,919 - model_manager - INFO - Setting up dataset provider...\n",
            "Resolving data files: 100% 339/339 [00:00<00:00, 1243.37it/s]\n",
            "Resolving data files: 100% 339/339 [00:00<00:00, 32622.90it/s]\n",
            "Resolving data files: 100% 128/128 [00:00<00:00, 547.90it/s]\n",
            "Resolving data files: 100% 128/128 [00:00<00:00, 138261.89it/s]\n",
            "2025-02-14 15:40:33,464 - model_manager - INFO - Dataset provider setup complete\n",
            "2025-02-14 15:40:35,923 - model_manager - INFO - Copied initial visualizations to equipped filenames\n",
            "2025-02-14 15:40:35,924 - model_manager - INFO - Current VRAM usage: 2492.1MB\n",
            "2025-02-14 15:41:08,380 - model_manager - INFO - Creating new experimental model from equipped model\n",
            "2025-02-14 15:41:08,451 - model_manager - INFO - Current VRAM usage: 3729.9MB\n",
            "2025-02-14 15:41:08,452 - model_manager - INFO - Pruning experimental model to 70.0% sparsity\n",
            "2025-02-14 15:41:19,170 - model_manager - INFO - Training experimental model: epochs=1, steps=100\n",
            "/usr/local/lib/python3.11/dist-packages/torchmetrics/functional/image/lpips.py:323: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.load_state_dict(torch.load(model_path, map_location=\"cpu\"), strict=False)\n",
            "/usr/local/lib/python3.11/dist-packages/efficientvit/apps/trainer/base.py:223: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.enable_amp)\n",
            "2025-02-14 15:41:20,162 - model_manager - INFO - Trainer setup complete\n",
            "2025-02-14 15:41:20,162 - model_manager - INFO - Starting training...\n",
            "Training Epoch #0: 100% 100/100 [02:01<00:00,  1.19s/it, loss=0.163, recon_loss=0.144, perceptual_loss=0.195, lr=2.1e-5]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <dcaecore.pacman_dataset_copy.StreamingPacmanDataset object at 0x7db598691310> was reported to be 100(when accessing len(dataloader)), but 101 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.\n",
            "  warnings.warn(warn_msg)\n",
            "Training Epoch #0: 100% 100/100 [02:02<00:00,  1.22s/it, loss=0.163, recon_loss=0.144, perceptual_loss=0.195, lr=2.1e-5]\n",
            "Validation Epoch #0: 100% 100/100 [00:37<00:00,  2.65it/s, loss=0.0624, recon_loss=0.0572, perceptual_loss=0.0523, psnr=18.5, ssim=nan, lpips=0.0523]\n",
            "Epoch 0: train_loss=0.1633, val_loss=0.0624, val_psnr=18.48, val_ssim=nan, val_lpips=0.0523\n",
            "2025-02-14 15:44:12,628 - matplotlib.image - WARNING - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.16894442..1.1653569].\n",
            "2025-02-14 15:44:12,891 - model_manager - INFO - Saved reconstruction comparison to output/reconstructions_after_training.png\n",
            "2025-02-14 15:44:23,494 - model_manager - INFO - Saved weight distribution to output/weight_dist_after_training.png\n",
            "2025-02-14 15:45:11,242 - model_manager - INFO - Equipping experimental model\n",
            "2025-02-14 15:45:13,342 - matplotlib.image - WARNING - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.16894442..1.1653569].\n",
            "2025-02-14 15:45:13,555 - model_manager - INFO - Saved reconstruction comparison to output/reconstructions_equipped.png\n",
            "2025-02-14 15:45:24,438 - model_manager - INFO - Saved weight distribution to output/weight_dist_equipped.png\n",
            "2025-02-14 15:45:24,439 - model_manager - INFO - Current VRAM usage: 2835.0MB\n",
            "2025-02-14 15:45:52,929 - model_manager - INFO - Creating new experimental model from equipped model\n",
            "2025-02-14 15:45:53,013 - model_manager - INFO - Current VRAM usage: 4390.2MB\n",
            "2025-02-14 15:45:53,013 - model_manager - INFO - Pruning experimental model to 50.0% sparsity\n",
            "2025-02-14 15:46:18,600 - model_manager - INFO - Training experimental model: epochs=1, steps=100\n",
            "2025-02-14 15:46:19,313 - model_manager - INFO - Trainer setup complete\n",
            "2025-02-14 15:46:19,314 - model_manager - INFO - Starting training...\n",
            "Training Epoch #0: 100% 100/100 [02:03<00:00,  1.24s/it, loss=0.0375, recon_loss=0.0333, perceptual_loss=0.0415, lr=2.1e-5]\n",
            "Validation Epoch #0: 100% 100/100 [00:39<00:00,  2.52it/s, loss=0.0147, recon_loss=0.0127, perceptual_loss=0.0196, psnr=25.3, ssim=nan, lpips=0.0196]\n",
            "Epoch 0: train_loss=0.0375, val_loss=0.0147, val_psnr=25.26, val_ssim=nan, val_lpips=0.0196\n",
            "2025-02-14 15:49:15,779 - matplotlib.image - WARNING - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.25943738..1.251678].\n",
            "2025-02-14 15:49:16,140 - model_manager - INFO - Saved reconstruction comparison to output/reconstructions_after_training.png\n",
            "2025-02-14 15:49:26,160 - model_manager - INFO - Saved weight distribution to output/weight_dist_after_training.png\n",
            "2025-02-14 15:50:16,753 - model_manager - INFO - Equipping experimental model\n",
            "2025-02-14 15:50:18,934 - matplotlib.image - WARNING - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.25943738..1.251678].\n",
            "2025-02-14 15:50:19,149 - model_manager - INFO - Saved reconstruction comparison to output/reconstructions_equipped.png\n",
            "2025-02-14 15:50:29,643 - model_manager - INFO - Saved weight distribution to output/weight_dist_equipped.png\n",
            "2025-02-14 15:50:29,643 - model_manager - INFO - Current VRAM usage: 2853.8MB\n",
            "2025-02-14 15:50:46,486 - model_manager - INFO - Creating new experimental model from equipped model\n",
            "2025-02-14 15:50:46,569 - model_manager - INFO - Current VRAM usage: 4408.8MB\n",
            "2025-02-14 15:50:46,569 - model_manager - INFO - Pruning experimental model to 85.0% sparsity\n",
            "2025-02-14 15:51:18,709 - model_manager - INFO - Pruning experimental model to 20.0% sparsity\n",
            "2025-02-14 15:51:30,773 - model_manager - INFO - Pruning experimental model to 20.0% sparsity\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 0.0.0.0:7860 <> https://b1befb49013d2cd33e.gradio.live\n",
            "[rank0]:[W214 15:51:40.074639636 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_gF80yz-wyd"
      },
      "source": [
        "## View Results\n",
        "\n",
        "The results are saved in the `output` directory:\n",
        "- Pruning analysis reports\n",
        "- Reconstructed images\n",
        "- Model statistics"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8837151c03ad4469a6b8818b80ea1ef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df55aae07979479b9522a54607080454",
              "IPY_MODEL_ca1f1ca7ae594658bf4bdb3c883dd658",
              "IPY_MODEL_49ce602dfc064005aa89e6c1e913db90"
            ],
            "layout": "IPY_MODEL_de2dba06b609443c8c1516a9ca0643ec"
          }
        },
        "df55aae07979479b9522a54607080454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bda2af07a55c46d1afd6c22ee7fb8d67",
            "placeholder": "​",
            "style": "IPY_MODEL_f961716071044e4f864e862e750aa61d",
            "value": "Resolving data files: 100%"
          }
        },
        "ca1f1ca7ae594658bf4bdb3c883dd658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e8a804eb73a48a8b920f96cec89657d",
            "max": 339,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f64ae2be498f41938cef054ebcaaa391",
            "value": 339
          }
        },
        "49ce602dfc064005aa89e6c1e913db90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76599e70b2094050a9ba799eb985ce39",
            "placeholder": "​",
            "style": "IPY_MODEL_921d7c11133342dd8bb3cb6634015cf6",
            "value": " 339/339 [00:00&lt;00:00, 19.67it/s]"
          }
        },
        "de2dba06b609443c8c1516a9ca0643ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bda2af07a55c46d1afd6c22ee7fb8d67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f961716071044e4f864e862e750aa61d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e8a804eb73a48a8b920f96cec89657d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f64ae2be498f41938cef054ebcaaa391": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76599e70b2094050a9ba799eb985ce39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "921d7c11133342dd8bb3cb6634015cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f52fc81fbe1f46778550108f44c7a17c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6c4599c8da3431183443487e356f362",
              "IPY_MODEL_fb8ca64e2c54456a993734b94278f5aa",
              "IPY_MODEL_a04d58edc22f4570b8c030b2697e0374"
            ],
            "layout": "IPY_MODEL_d9acf1676726443bb9f758117090472e"
          }
        },
        "c6c4599c8da3431183443487e356f362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2021055773e44b7db7348413b3eb84b3",
            "placeholder": "​",
            "style": "IPY_MODEL_36c168d1943e4bb3acd8421c2b86788e",
            "value": "Resolving data files: 100%"
          }
        },
        "fb8ca64e2c54456a993734b94278f5aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e949139f79c74e78822d009aefc7514c",
            "max": 339,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d23cab0254047cb8279321310c686a8",
            "value": 339
          }
        },
        "a04d58edc22f4570b8c030b2697e0374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a111af659eb47028e57a222d6ac9fd3",
            "placeholder": "​",
            "style": "IPY_MODEL_20bc563ae3034b75afbe83094109e87c",
            "value": " 339/339 [00:00&lt;00:00, 10382.17it/s]"
          }
        },
        "d9acf1676726443bb9f758117090472e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2021055773e44b7db7348413b3eb84b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36c168d1943e4bb3acd8421c2b86788e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e949139f79c74e78822d009aefc7514c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d23cab0254047cb8279321310c686a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a111af659eb47028e57a222d6ac9fd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20bc563ae3034b75afbe83094109e87c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}