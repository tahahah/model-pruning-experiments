{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPSqBmQM-wyG"
      },
      "source": [
        "# Model Pruning Experiments\n",
        "\n",
        "This notebook demonstrates pruning experiments on:\n",
        "1. Vision Transformer (ViT)\n",
        "2. Deep Compression AutoEncoder (DC-AE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ugpz1ix5-wyM",
        "outputId": "189c0d7b-a7cc-4969-f469-dabc454b50ea"
      },
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/tahahah/model-pruning-experiments.git\n",
        "%cd model-pruning-experiments\n",
        "\n",
        "# Install dependencies\n",
        "!pip install -r requirements.txt"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'model-pruning-experiments'...\n",
            "remote: Enumerating objects: 124, done.\u001b[K\n",
            "remote: Counting objects: 100% (124/124), done.\u001b[K\n",
            "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
            "remote: Total 124 (delta 59), reused 86 (delta 28), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (124/124), 464.35 KiB | 8.76 MiB/s, done.\n",
            "Resolving deltas: 100% (59/59), done.\n",
            "/content/model-pruning-experiments\n",
            "Collecting git+https://github.com/mit-han-lab/efficientvit.git (from -r requirements.txt (line 4))\n",
            "  Cloning https://github.com/mit-han-lab/efficientvit.git to /tmp/pip-req-build-f9tzhr1q\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/mit-han-lab/efficientvit.git /tmp/pip-req-build-f9tzhr1q\n",
            "  Resolved https://github.com/mit-han-lab/efficientvit.git to commit b94ff779828eea399c78f626b574da2d50ef2e49\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.20.1+cu124)\n",
            "Collecting torch-pruning>=1.1.0 (from -r requirements.txt (line 3))\n",
            "  Downloading torch_pruning-1.5.1-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (2.2.2)\n",
            "Requirement already satisfied: Pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (11.1.0)\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.15.0->-r requirements.txt (line 2)) (1.26.4)\n",
            "Collecting tinyneuralnetwork@ git+https://github.com/alibaba/TinyNeuralNetwork.git (from efficientvit==0.0.0->-r requirements.txt (line 4))\n",
            "  Cloning https://github.com/alibaba/TinyNeuralNetwork.git to /tmp/pip-install-tpk6ff6c/tinyneuralnetwork_400aa4ee2dc845208465fd249e1c1df3\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/alibaba/TinyNeuralNetwork.git /tmp/pip-install-tpk6ff6c/tinyneuralnetwork_400aa4ee2dc845208465fd249e1c1df3\n",
            "  Resolved https://github.com/alibaba/TinyNeuralNetwork.git to commit fac2af5545167bbf0658a545ea68d14553d903b4\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting segment_anything@ git+https://github.com/facebookresearch/segment-anything.git (from efficientvit==0.0.0->-r requirements.txt (line 4))\n",
            "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-install-tpk6ff6c/segment-anything_4e18b4a0ae8d44a4ad8fe697501a63bf\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-install-tpk6ff6c/segment-anything_4e18b4a0ae8d44a4ad8fe697501a63bf\n",
            "  Resolved https://github.com/facebookresearch/segment-anything.git to commit dca509fe793f601edb92606367a655c15ac00fdf\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchmetrics (from efficientvit==0.0.0->-r requirements.txt (line 4))\n",
            "  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from efficientvit==0.0.0->-r requirements.txt (line 4)) (1.0.14)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from efficientvit==0.0.0->-r requirements.txt (line 4)) (0.8.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from efficientvit==0.0.0->-r requirements.txt (line 4)) (4.11.0.86)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from efficientvit==0.0.0->-r requirements.txt (line 4)) (4.67.1)\n",
            "Collecting torchprofile (from efficientvit==0.0.0->-r requirements.txt (line 4))\n",
            "  Downloading torchprofile-0.0.4-py3-none-any.whl.metadata (303 bytes)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from efficientvit==0.0.0->-r requirements.txt (line 4)) (1.13.1)\n",
            "Collecting torch-fidelity (from efficientvit==0.0.0->-r requirements.txt (line 4))\n",
            "  Downloading torch_fidelity-0.3.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from efficientvit==0.0.0->-r requirements.txt (line 4)) (0.32.2)\n",
            "Collecting omegaconf (from efficientvit==0.0.0->-r requirements.txt (line 4))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting ipdb (from efficientvit==0.0.0->-r requirements.txt (line 4))\n",
            "  Downloading ipdb-0.13.13-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from efficientvit==0.0.0->-r requirements.txt (line 4)) (0.19.6)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from efficientvit==0.0.0->-r requirements.txt (line 4)) (0.28.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from efficientvit==0.0.0->-r requirements.txt (line 4)) (4.48.2)\n",
            "Collecting onnx (from efficientvit==0.0.0->-r requirements.txt (line 4))\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxsim (from efficientvit==0.0.0->-r requirements.txt (line 4))\n",
            "  Downloading onnxsim-0.4.36-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting onnxruntime (from efficientvit==0.0.0->-r requirements.txt (line 4))\n",
            "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from efficientvit==0.0.0->-r requirements.txt (line 4)) (2.0.8)\n",
            "Collecting lvis (from efficientvit==0.0.0->-r requirements.txt (line 4))\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl.metadata (856 bytes)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from efficientvit==0.0.0->-r requirements.txt (line 4)) (0.25.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 5)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 5)) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 7)) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 7)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 7)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 7)) (3.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->-r requirements.txt (line 5)) (1.17.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->efficientvit==0.0.0->-r requirements.txt (line 4)) (8.6.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers->efficientvit==0.0.0->-r requirements.txt (line 4)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers->efficientvit==0.0.0->-r requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers->efficientvit==0.0.0->-r requirements.txt (line 4)) (0.5.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->efficientvit==0.0.0->-r requirements.txt (line 4)) (6.0.2)\n",
            "Requirement already satisfied: ipython>=7.31.1 in /usr/local/lib/python3.11/dist-packages (from ipdb->efficientvit==0.0.0->-r requirements.txt (line 4)) (7.34.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipdb->efficientvit==0.0.0->-r requirements.txt (line 4)) (4.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->-r requirements.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.11/dist-packages (from lvis->efficientvit==0.0.0->-r requirements.txt (line 4)) (3.0.11)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->efficientvit==0.0.0->-r requirements.txt (line 4))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx->efficientvit==0.0.0->-r requirements.txt (line 4)) (4.25.6)\n",
            "Collecting coloredlogs (from onnxruntime->efficientvit==0.0.0->-r requirements.txt (line 4))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime->efficientvit==0.0.0->-r requirements.txt (line 4)) (25.1.24)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from onnxsim->efficientvit==0.0.0->-r requirements.txt (line 4)) (13.9.4)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientvit==0.0.0->-r requirements.txt (line 4)) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientvit==0.0.0->-r requirements.txt (line 4)) (2025.1.10)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientvit==0.0.0->-r requirements.txt (line 4)) (0.4)\n",
            "Collecting ruamel.yaml>=0.16.12 (from tinyneuralnetwork@ git+https://github.com/alibaba/TinyNeuralNetwork.git->efficientvit==0.0.0->-r requirements.txt (line 4))\n",
            "  Downloading ruamel.yaml-0.18.10-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting igraph>=0.9 (from tinyneuralnetwork@ git+https://github.com/alibaba/TinyNeuralNetwork.git->efficientvit==0.0.0->-r requirements.txt (line 4))\n",
            "  Downloading igraph-0.11.8-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics->efficientvit==0.0.0->-r requirements.txt (line 4))\n",
            "  Downloading lightning_utilities-0.12.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->efficientvit==0.0.0->-r requirements.txt (line 4)) (0.21.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->efficientvit==0.0.0->-r requirements.txt (line 4)) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->efficientvit==0.0.0->-r requirements.txt (line 4)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->efficientvit==0.0.0->-r requirements.txt (line 4)) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->efficientvit==0.0.0->-r requirements.txt (line 4)) (4.3.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->efficientvit==0.0.0->-r requirements.txt (line 4)) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb->efficientvit==0.0.0->-r requirements.txt (line 4)) (2.10.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->efficientvit==0.0.0->-r requirements.txt (line 4)) (2.20.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->efficientvit==0.0.0->-r requirements.txt (line 4)) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb->efficientvit==0.0.0->-r requirements.txt (line 4)) (75.1.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->efficientvit==0.0.0->-r requirements.txt (line 4)) (4.0.12)\n",
            "Collecting texttable>=1.6.2 (from igraph>=0.9->tinyneuralnetwork@ git+https://github.com/alibaba/TinyNeuralNetwork.git->efficientvit==0.0.0->-r requirements.txt (line 4))\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting jedi>=0.16 (from ipython>=7.31.1->ipdb->efficientvit==0.0.0->-r requirements.txt (line 4))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.31.1->ipdb->efficientvit==0.0.0->-r requirements.txt (line 4)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.31.1->ipdb->efficientvit==0.0.0->-r requirements.txt (line 4)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.31.1->ipdb->efficientvit==0.0.0->-r requirements.txt (line 4)) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.31.1->ipdb->efficientvit==0.0.0->-r requirements.txt (line 4)) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.31.1->ipdb->efficientvit==0.0.0->-r requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=7.31.1->ipdb->efficientvit==0.0.0->-r requirements.txt (line 4)) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.31.1->ipdb->efficientvit==0.0.0->-r requirements.txt (line 4)) (4.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->efficientvit==0.0.0->-r requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->efficientvit==0.0.0->-r requirements.txt (line 4)) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers->efficientvit==0.0.0->-r requirements.txt (line 4)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers->efficientvit==0.0.0->-r requirements.txt (line 4)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers->efficientvit==0.0.0->-r requirements.txt (line 4)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers->efficientvit==0.0.0->-r requirements.txt (line 4)) (2025.1.31)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.16.12->tinyneuralnetwork@ git+https://github.com/alibaba/TinyNeuralNetwork.git->efficientvit==0.0.0->-r requirements.txt (line 4))\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->efficientvit==0.0.0->-r requirements.txt (line 4))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers->efficientvit==0.0.0->-r requirements.txt (line 4)) (3.21.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->onnxsim->efficientvit==0.0.0->-r requirements.txt (line 4)) (3.0.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->efficientvit==0.0.0->-r requirements.txt (line 4)) (5.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.31.1->ipdb->efficientvit==0.0.0->-r requirements.txt (line 4)) (0.8.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->onnxsim->efficientvit==0.0.0->-r requirements.txt (line 4)) (0.1.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=7.31.1->ipdb->efficientvit==0.0.0->-r requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.31.1->ipdb->efficientvit==0.0.0->-r requirements.txt (line 4)) (0.2.13)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m787.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_pruning-1.5.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipdb-0.13.13-py3-none-any.whl (12 kB)\n",
            "Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxsim-0.4.36-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\n",
            "Downloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchprofile-0.0.4-py3-none-any.whl (7.7 kB)\n",
            "Downloading igraph-0.11.8-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.12.0-py3-none-any.whl (28 kB)\n",
            "Downloading ruamel.yaml-0.18.10-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Building wheels for collected packages: efficientvit, antlr4-python3-runtime, segment_anything, tinyneuralnetwork\n",
            "  Building wheel for efficientvit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientvit: filename=efficientvit-0.0.0-py3-none-any.whl size=191638 sha256=2b72c5e57b4c54b4bcb0006b0250514c9b3f5b35923cf1d5195e175cebf6fced\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-eux4hlbj/wheels/ca/75/b0/ee319e23d76191fa53181c9868245652ca7c2c13889ccbf0a7\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=ed0602e4730417af4865dc2591c3f9e538326647b2f51bcb0f2121dce00c4fcd\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "  Building wheel for segment_anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segment_anything: filename=segment_anything-1.0-py3-none-any.whl size=36592 sha256=bbbc0217e2dd02edb2027f744b2007d1a5acfe5021be66809047d9726e273a30\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-eux4hlbj/wheels/15/d7/bd/05f5f23b7dcbe70cbc6783b06f12143b0cf1a5da5c7b52dcc5\n",
            "  Building wheel for tinyneuralnetwork (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinyneuralnetwork: filename=TinyNeuralNetwork-0.1.0.20241219143703+fac2af5545167bbf0658a545ea68d14553d903b4-py3-none-any.whl size=432378 sha256=611c0562a3ad46ca9044c9a753e396561346b7f2b7a7d42ff63320e7c08652f5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-eux4hlbj/wheels/c3/ec/93/b3431fc1bd188afd12c9b9db8b84ed658027401277e931f205\n",
            "Successfully built efficientvit antlr4-python3-runtime segment_anything tinyneuralnetwork\n",
            "Installing collected packages: texttable, segment_anything, antlr4-python3-runtime, ruamel.yaml.clib, onnx, omegaconf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, jedi, igraph, humanfriendly, ruamel.yaml, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, tinyneuralnetwork, onnxsim, onnxruntime, nvidia-cusolver-cu12, lvis, ipdb, torchmetrics, torch-pruning, torchprofile, torch-fidelity, efficientvit\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 coloredlogs-15.0.1 efficientvit-0.0.0 humanfriendly-10.0 igraph-0.11.8 ipdb-0.13.13 jedi-0.19.2 lightning-utilities-0.12.0 lvis-0.5.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 omegaconf-2.3.0 onnx-1.17.0 onnxruntime-1.20.1 onnxsim-0.4.36 ruamel.yaml-0.18.10 ruamel.yaml.clib-0.2.12 segment_anything-1.0 texttable-1.7.0 tinyneuralnetwork-0.1.0.20241219143703+fac2af5545167bbf0658a545ea68d14553d903b4 torch-fidelity-0.3.0 torch-pruning-1.5.1 torchmetrics-1.6.1 torchprofile-0.0.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "cfe8d1ed7d4f4046ba2ca3bd0f2268bb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr9AYTje-wyb"
      },
      "source": [
        "## 1. Vision Transformer (ViT) Pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twuJHYxZ-wyb"
      },
      "source": [
        "from vit_pruning_analysis import *\n",
        "\n",
        "# Run ViT pruning analysis\n",
        "main()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfQXndbB-wyc"
      },
      "source": [
        "## 2. DC-AE Pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xazu2nV4-wyc",
        "outputId": "68c192c2-f4cd-446c-ff7f-624c7390a740"
      },
      "source": [
        "!git stash && git pull"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved working directory and index state WIP on master: 74f3dfa fix: incorrect import utils\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python vae_pruning_analysis.py"
      ],
      "metadata": {
        "id": "vLT2n6GPhd2c",
        "outputId": "56efca9b-5d17-4afe-edf8-567751545561",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading DC-AE model...\n",
            "\n",
            "Analyzing original model...\n",
            "\n",
            "Model Sparsity Analysis:\n",
            "Total Parameters: 676,475,584\n",
            "Non-zero Parameters: 676,475,584 (100.0%)\n",
            "Zero Parameters: 0 (0.0%)\n",
            "\n",
            "Top 10 Most Sparse Layers:\n",
            "                                                                      Layer      Size   NonZero  Sparsity(%)\n",
            "147                          decoder.project_out.op_list.2.conv.conv.weight     27648     27648          0.0\n",
            "0                                       encoder.project_in.conv.conv.weight      1728      1728          0.0\n",
            "1                         encoder.stages.1.op_list.0.main.conv1.conv.weight    589824    589824          0.0\n",
            "2                         encoder.stages.1.op_list.0.main.conv2.conv.weight    589824    589824          0.0\n",
            "132          decoder.stages.5.op_list.2.context_module.main.qkv.conv.weight   3145728   3145728          0.0\n",
            "133         decoder.stages.5.op_list.2.context_module.main.proj.conv.weight   1048576   1048576          0.0\n",
            "134  decoder.stages.5.op_list.2.local_module.main.inverted_conv.conv.weight   8388608   8388608          0.0\n",
            "135     decoder.stages.5.op_list.2.local_module.main.depth_conv.conv.weight     73728     73728          0.0\n",
            "136     decoder.stages.5.op_list.2.local_module.main.point_conv.conv.weight   4194304   4194304          0.0\n",
            "137          decoder.stages.6.op_list.0.context_module.main.qkv.conv.weight  12582912  12582912          0.0\n",
            "\n",
            "Processing media_images_image_2810940_edf08e2644ac8ed7a8d8.png with sparsity 0.0\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.14399809..1.2100072].\n",
            "Figure(1000x500)\n",
            "\n",
            "Model Sparsity Analysis:\n",
            "Total Parameters: 676,475,584\n",
            "Non-zero Parameters: 676,475,584 (100.0%)\n",
            "Zero Parameters: 0 (0.0%)\n",
            "\n",
            "Top 10 Most Sparse Layers:\n",
            "                                                                      Layer      Size   NonZero  Sparsity(%)\n",
            "147                          decoder.project_out.op_list.2.conv.conv.weight     27648     27648          0.0\n",
            "0                                       encoder.project_in.conv.conv.weight      1728      1728          0.0\n",
            "1                         encoder.stages.1.op_list.0.main.conv1.conv.weight    589824    589824          0.0\n",
            "2                         encoder.stages.1.op_list.0.main.conv2.conv.weight    589824    589824          0.0\n",
            "132          decoder.stages.5.op_list.2.context_module.main.qkv.conv.weight   3145728   3145728          0.0\n",
            "133         decoder.stages.5.op_list.2.context_module.main.proj.conv.weight   1048576   1048576          0.0\n",
            "134  decoder.stages.5.op_list.2.local_module.main.inverted_conv.conv.weight   8388608   8388608          0.0\n",
            "135     decoder.stages.5.op_list.2.local_module.main.depth_conv.conv.weight     73728     73728          0.0\n",
            "136     decoder.stages.5.op_list.2.local_module.main.point_conv.conv.weight   4194304   4194304          0.0\n",
            "137          decoder.stages.6.op_list.0.context_module.main.qkv.conv.weight  12582912  12582912          0.0\n",
            "\n",
            "Processing media_images_image_2810940_edf08e2644ac8ed7a8d8.png with sparsity 0.5\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.14641541..1.1120931].\n",
            "Figure(1000x500)\n",
            "\n",
            "Model Sparsity Analysis:\n",
            "Total Parameters: 676,475,584\n",
            "Non-zero Parameters: 338,237,783 (50.0%)\n",
            "Zero Parameters: 338,237,801 (50.0%)\n",
            "\n",
            "Top 10 Most Sparse Layers:\n",
            "                                                                      Layer      Size   NonZero  Sparsity(%)\n",
            "121          decoder.stages.4.op_list.2.context_module.main.qkv.conv.weight   3145728   1572863    50.000032\n",
            "47      encoder.stages.4.op_list.1.local_module.main.point_conv.conv.weight   4194304   2097151    50.000024\n",
            "123  decoder.stages.4.op_list.2.local_module.main.inverted_conv.conv.weight   8388608   4194303    50.000012\n",
            "141     decoder.stages.6.op_list.0.local_module.main.point_conv.conv.weight  16777216   8388607    50.000006\n",
            "144  decoder.stages.6.op_list.1.local_module.main.inverted_conv.conv.weight  33554432  16777214    50.000006\n",
            "115                        decoder.stages.4.op_list.0.main.conv.conv.weight  37748736  18874366    50.000005\n",
            "126                        decoder.stages.5.op_list.0.main.conv.conv.weight  75497472  37748735    50.000001\n",
            "95                        decoder.stages.2.op_list.6.main.conv2.conv.weight   2359296   1179648    50.000000\n",
            "96                        decoder.stages.2.op_list.7.main.conv1.conv.weight   2359296   1179648    50.000000\n",
            "97                        decoder.stages.2.op_list.7.main.conv2.conv.weight   2359296   1179648    50.000000\n",
            "\n",
            "Processing media_images_image_2810940_edf08e2644ac8ed7a8d8.png with sparsity 0.7\n",
            "Figure(1000x500)\n",
            "\n",
            "Model Sparsity Analysis:\n",
            "Total Parameters: 676,475,584\n",
            "Non-zero Parameters: 202,942,697 (30.0%)\n",
            "Zero Parameters: 473,532,887 (70.0%)\n",
            "\n",
            "Top 10 Most Sparse Layers:\n",
            "                                                                   Layer    Size  NonZero  Sparsity(%)\n",
            "108  decoder.stages.3.op_list.1.local_module.main.depth_conv.conv.weight   36864    11059    70.000543\n",
            "113  decoder.stages.3.op_list.2.local_module.main.depth_conv.conv.weight   36864    11059    70.000543\n",
            "30   encoder.stages.3.op_list.0.local_module.main.depth_conv.conv.weight   36864    11059    70.000543\n",
            "35   encoder.stages.3.op_list.1.local_module.main.depth_conv.conv.weight   36864    11059    70.000543\n",
            "28       encoder.stages.3.op_list.0.context_module.main.proj.conv.weight  262144    78643    70.000076\n",
            "33       encoder.stages.3.op_list.1.context_module.main.proj.conv.weight  262144    78643    70.000076\n",
            "106      decoder.stages.3.op_list.1.context_module.main.proj.conv.weight  262144    78643    70.000076\n",
            "111      decoder.stages.3.op_list.2.context_module.main.proj.conv.weight  262144    78643    70.000076\n",
            "82                     decoder.stages.1.op_list.5.main.conv2.conv.weight  589824   176947    70.000034\n",
            "74                     decoder.stages.1.op_list.1.main.conv2.conv.weight  589824   176947    70.000034\n",
            "\n",
            "Processing media_images_image_2810940_edf08e2644ac8ed7a8d8.png with sparsity 0.9\n",
            "Figure(1000x500)\n",
            "\n",
            "Model Sparsity Analysis:\n",
            "Total Parameters: 676,475,584\n",
            "Non-zero Parameters: 67,647,614 (10.0%)\n",
            "Zero Parameters: 608,827,970 (90.0%)\n",
            "\n",
            "Top 10 Most Sparse Layers:\n",
            "                                                                      Layer      Size  NonZero  Sparsity(%)\n",
            "102                      decoder.stages.2.op_list.10.main.conv1.conv.weight   2359296   235929    90.000025\n",
            "15                        encoder.stages.2.op_list.2.main.conv2.conv.weight   2359296   235929    90.000025\n",
            "49           encoder.stages.5.op_list.0.context_module.main.qkv.conv.weight   3145728   314572    90.000025\n",
            "129  decoder.stages.5.op_list.1.local_module.main.inverted_conv.conv.weight   8388608   838859    90.000021\n",
            "131     decoder.stages.5.op_list.1.local_module.main.point_conv.conv.weight   4194304   419430    90.000010\n",
            "47      encoder.stages.4.op_list.1.local_module.main.point_conv.conv.weight   4194304   419430    90.000010\n",
            "139  decoder.stages.6.op_list.0.local_module.main.inverted_conv.conv.weight  33554432  3355442    90.000004\n",
            "67   encoder.stages.6.op_list.1.local_module.main.inverted_conv.conv.weight  33554432  3355442    90.000004\n",
            "137          decoder.stages.6.op_list.0.context_module.main.qkv.conv.weight  12582912  1258291    90.000002\n",
            "126                        decoder.stages.5.op_list.0.main.conv.conv.weight  75497472  7549746    90.000002\n",
            "\n",
            "Processing media_images_image_47095_fbef6038d915823a1016.png with sparsity 0.0\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.14384192..1.1544229].\n",
            "Figure(1000x500)\n",
            "\n",
            "Model Sparsity Analysis:\n",
            "Total Parameters: 676,475,584\n",
            "Non-zero Parameters: 676,475,584 (100.0%)\n",
            "Zero Parameters: 0 (0.0%)\n",
            "\n",
            "Top 10 Most Sparse Layers:\n",
            "                                                                      Layer      Size   NonZero  Sparsity(%)\n",
            "147                          decoder.project_out.op_list.2.conv.conv.weight     27648     27648          0.0\n",
            "0                                       encoder.project_in.conv.conv.weight      1728      1728          0.0\n",
            "1                         encoder.stages.1.op_list.0.main.conv1.conv.weight    589824    589824          0.0\n",
            "2                         encoder.stages.1.op_list.0.main.conv2.conv.weight    589824    589824          0.0\n",
            "132          decoder.stages.5.op_list.2.context_module.main.qkv.conv.weight   3145728   3145728          0.0\n",
            "133         decoder.stages.5.op_list.2.context_module.main.proj.conv.weight   1048576   1048576          0.0\n",
            "134  decoder.stages.5.op_list.2.local_module.main.inverted_conv.conv.weight   8388608   8388608          0.0\n",
            "135     decoder.stages.5.op_list.2.local_module.main.depth_conv.conv.weight     73728     73728          0.0\n",
            "136     decoder.stages.5.op_list.2.local_module.main.point_conv.conv.weight   4194304   4194304          0.0\n",
            "137          decoder.stages.6.op_list.0.context_module.main.qkv.conv.weight  12582912  12582912          0.0\n",
            "\n",
            "Processing media_images_image_47095_fbef6038d915823a1016.png with sparsity 0.5\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.18849158..1.1738203].\n",
            "Figure(1000x500)\n",
            "\n",
            "Model Sparsity Analysis:\n",
            "Total Parameters: 676,475,584\n",
            "Non-zero Parameters: 338,237,783 (50.0%)\n",
            "Zero Parameters: 338,237,801 (50.0%)\n",
            "\n",
            "Top 10 Most Sparse Layers:\n",
            "                                                                      Layer      Size   NonZero  Sparsity(%)\n",
            "121          decoder.stages.4.op_list.2.context_module.main.qkv.conv.weight   3145728   1572863    50.000032\n",
            "47      encoder.stages.4.op_list.1.local_module.main.point_conv.conv.weight   4194304   2097151    50.000024\n",
            "123  decoder.stages.4.op_list.2.local_module.main.inverted_conv.conv.weight   8388608   4194303    50.000012\n",
            "141     decoder.stages.6.op_list.0.local_module.main.point_conv.conv.weight  16777216   8388607    50.000006\n",
            "144  decoder.stages.6.op_list.1.local_module.main.inverted_conv.conv.weight  33554432  16777214    50.000006\n",
            "115                        decoder.stages.4.op_list.0.main.conv.conv.weight  37748736  18874366    50.000005\n",
            "126                        decoder.stages.5.op_list.0.main.conv.conv.weight  75497472  37748735    50.000001\n",
            "95                        decoder.stages.2.op_list.6.main.conv2.conv.weight   2359296   1179648    50.000000\n",
            "96                        decoder.stages.2.op_list.7.main.conv1.conv.weight   2359296   1179648    50.000000\n",
            "97                        decoder.stages.2.op_list.7.main.conv2.conv.weight   2359296   1179648    50.000000\n",
            "\n",
            "Processing media_images_image_47095_fbef6038d915823a1016.png with sparsity 0.7\n",
            "Figure(1000x500)\n",
            "\n",
            "Model Sparsity Analysis:\n",
            "Total Parameters: 676,475,584\n",
            "Non-zero Parameters: 202,942,697 (30.0%)\n",
            "Zero Parameters: 473,532,887 (70.0%)\n",
            "\n",
            "Top 10 Most Sparse Layers:\n",
            "                                                                   Layer    Size  NonZero  Sparsity(%)\n",
            "108  decoder.stages.3.op_list.1.local_module.main.depth_conv.conv.weight   36864    11059    70.000543\n",
            "113  decoder.stages.3.op_list.2.local_module.main.depth_conv.conv.weight   36864    11059    70.000543\n",
            "30   encoder.stages.3.op_list.0.local_module.main.depth_conv.conv.weight   36864    11059    70.000543\n",
            "35   encoder.stages.3.op_list.1.local_module.main.depth_conv.conv.weight   36864    11059    70.000543\n",
            "28       encoder.stages.3.op_list.0.context_module.main.proj.conv.weight  262144    78643    70.000076\n",
            "33       encoder.stages.3.op_list.1.context_module.main.proj.conv.weight  262144    78643    70.000076\n",
            "106      decoder.stages.3.op_list.1.context_module.main.proj.conv.weight  262144    78643    70.000076\n",
            "111      decoder.stages.3.op_list.2.context_module.main.proj.conv.weight  262144    78643    70.000076\n",
            "82                     decoder.stages.1.op_list.5.main.conv2.conv.weight  589824   176947    70.000034\n",
            "74                     decoder.stages.1.op_list.1.main.conv2.conv.weight  589824   176947    70.000034\n",
            "\n",
            "Processing media_images_image_47095_fbef6038d915823a1016.png with sparsity 0.9\n",
            "Figure(1000x500)\n",
            "\n",
            "Model Sparsity Analysis:\n",
            "Total Parameters: 676,475,584\n",
            "Non-zero Parameters: 67,647,614 (10.0%)\n",
            "Zero Parameters: 608,827,970 (90.0%)\n",
            "\n",
            "Top 10 Most Sparse Layers:\n",
            "                                                                      Layer      Size  NonZero  Sparsity(%)\n",
            "102                      decoder.stages.2.op_list.10.main.conv1.conv.weight   2359296   235929    90.000025\n",
            "15                        encoder.stages.2.op_list.2.main.conv2.conv.weight   2359296   235929    90.000025\n",
            "49           encoder.stages.5.op_list.0.context_module.main.qkv.conv.weight   3145728   314572    90.000025\n",
            "129  decoder.stages.5.op_list.1.local_module.main.inverted_conv.conv.weight   8388608   838859    90.000021\n",
            "131     decoder.stages.5.op_list.1.local_module.main.point_conv.conv.weight   4194304   419430    90.000010\n",
            "47      encoder.stages.4.op_list.1.local_module.main.point_conv.conv.weight   4194304   419430    90.000010\n",
            "139  decoder.stages.6.op_list.0.local_module.main.inverted_conv.conv.weight  33554432  3355442    90.000004\n",
            "67   encoder.stages.6.op_list.1.local_module.main.inverted_conv.conv.weight  33554432  3355442    90.000004\n",
            "137          decoder.stages.6.op_list.0.context_module.main.qkv.conv.weight  12582912  1258291    90.000002\n",
            "126                        decoder.stages.5.op_list.0.main.conv.conv.weight  75497472  7549746    90.000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Finetuning DC AE"
      ],
      "metadata": {
        "id": "MDi_POmHzfvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!wandb login"
      ],
      "metadata": {
        "id": "fcG5NJ0Rz0Z4",
        "outputId": "7bccfe4e-6841-48ec-939d-57a51135c156",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtahaa\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git reset --hard && git pull\n"
      ],
      "metadata": {
        "id": "72A9bSwB3f7S",
        "outputId": "da49ee0f-adb3-4cc9-e846-390f4e0f9e0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HEAD is now at 62438f0 fix: batch size 1 to avoid vram issues\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (4/4), 588 bytes | 294.00 KiB/s, done.\n",
            "From https://github.com/tahahah/model-pruning-experiments\n",
            "   62438f0..ede3378  master     -> origin/master\n",
            "Updating 62438f0..ede3378\n",
            "Fast-forward\n",
            " dcaecore/trainer.py | 17 \u001b[32m++++++++++++++\u001b[m\u001b[31m---\u001b[m\n",
            " 1 file changed, 14 insertions(+), 3 deletions(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"RANK\"] = \"0\"\n",
        "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
        "os.environ[\"LOCAL_RANK\"] = \"0\"\n",
        "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
        "os.environ[\"MASTER_PORT\"] = \"29500\""
      ],
      "metadata": {
        "id": "FQ_VuyoaR-C-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python dcaecore/train_dc_ae.py --config dcaecore/config.yaml --pretrained \"mit-han-lab/dc-ae-f32c32-in-1.0\" --output_dir dcaecore/outputs --gpu 0"
      ],
      "metadata": {
        "id": "R6PlDQl0ze-j",
        "outputId": "70b421dd-cbc8-41bb-d4af-17bef639afab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resolving data files: 100% 339/339 [00:00<00:00, 345.17it/s]\n",
            "Resolving data files: 100% 339/339 [00:00<00:00, 463149.53it/s]\n",
            "len(train_dataset)=1000\n",
            "len(val_dataset)=1000\n",
            "len(test_dataset)=1000\n",
            "2025-02-13 09:00:25,728 - dcae_training - INFO - Set random seed to 42\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtahaa\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/model-pruning-experiments/wandb/run-20250213_090026-aibsj2dv\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mworldly-violet-11\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/tahaa/dcae-finetuning\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/tahaa/dcae-finetuning/runs/aibsj2dv\u001b[0m\n",
            "2025-02-13 09:00:27,257 - dcae_training - INFO - Initialized Weights & Biases logging\n",
            "2025-02-13 09:00:27,258 - dcae_training - INFO - Created data provider with batch size 1\n",
            "2025-02-13 09:00:27,258 - dcae_training - INFO - Loading pretrained model from mit-han-lab/dc-ae-f32c32-in-1.0\n",
            "2025-02-13 09:00:30,725 - dcae_training - INFO - Created training configuration\n",
            "/usr/local/lib/python3.11/dist-packages/torchmetrics/functional/image/lpips.py:323: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.load_state_dict(torch.load(model_path, map_location=\"cpu\"), strict=False)\n",
            "/usr/local/lib/python3.11/dist-packages/efficientvit/apps/trainer/base.py:223: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.enable_amp)\n",
            "2025-02-13 09:00:32,249 - dcae_training - INFO - Trainer setup complete\n",
            "2025-02-13 09:00:32,250 - dcae_training - INFO - Starting training...\n",
            "Training Epoch #0:  65% 647/1000 [12:06<06:38,  1.13s/it, loss=0.00259, recon_loss=0.00233, perceptual_loss=0.00262, lr=1.38e-5]'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 88c119c4-c101-4d20-9cde-607ac1497368)')' thrown while requesting GET https://huggingface.co/datasets/Tahahah/PacmanDataset_3/resolve/d395836536485d5cab6113f5dd90d551afc134d5/data/episode_1000_episode_1019/train-00000-of-00001.parquet\n",
            "Retrying in 1s [Retry 1/5].\n",
            "Training Epoch #0:  66% 655/1000 [12:23<07:34,  1.32s/it, loss=0.00258, recon_loss=0.00232, perceptual_loss=0.00261, lr=1.4e-5]'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: d149b470-50cc-4733-8328-52042e6a56d8)')' thrown while requesting GET https://huggingface.co/datasets/Tahahah/PacmanDataset_3/resolve/d395836536485d5cab6113f5dd90d551afc134d5/data/episode_1000_episode_1019/train-00000-of-00001.parquet\n",
            "Retrying in 1s [Retry 1/5].\n",
            "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: a0cc38b5-c31b-49b6-877e-e724f0f43ff8)')' thrown while requesting GET https://huggingface.co/datasets/Tahahah/PacmanDataset_3/resolve/d395836536485d5cab6113f5dd90d551afc134d5/data/episode_0_episode_19/train-00000-of-00001.parquet\n",
            "Retrying in 1s [Retry 1/5].\n",
            "Training Epoch #0:  77% 773/1000 [14:42<04:13,  1.11s/it, loss=0.0023, recon_loss=0.00207, perceptual_loss=0.00229, lr=1.63e-5]'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: a55d11ce-13f1-45d1-820c-5428fd3470d2)')' thrown while requesting GET https://huggingface.co/datasets/Tahahah/PacmanDataset_3/resolve/d395836536485d5cab6113f5dd90d551afc134d5/data/episode_1000_episode_1019/train-00000-of-00001.parquet\n",
            "Retrying in 1s [Retry 1/5].\n",
            "Training Epoch #0:  79% 789/1000 [15:08<03:54,  1.11s/it, loss=0.00227, recon_loss=0.00204, perceptual_loss=0.00225, lr=1.66e-5]'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: b10be6df-1cb4-4a6f-ab32-cee4fa25af20)')' thrown while requesting GET https://huggingface.co/datasets/Tahahah/PacmanDataset_3/resolve/d395836536485d5cab6113f5dd90d551afc134d5/data/episode_1000_episode_1019/train-00000-of-00001.parquet\n",
            "Retrying in 1s [Retry 1/5].\n",
            "Training Epoch #0: 100% 1000/1000 [19:10<00:00,  1.15s/it, loss=0.00187, recon_loss=0.00169, perceptual_loss=0.00182, lr=2.08e-5]\n",
            "Validation Epoch #0:   0% 1/1000 [00:04<1:12:57,  4.38s/it, loss=3.63e-5, recon_loss=1.15e-5, perceptual_loss=0.000248, psnr=59.2, ssim=0.995, lpips=0.000248]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/model-pruning-experiments/dcaecore/train_dc_ae.py\", line 253, in <module>\n",
            "    main()\n",
            "  File \"/content/model-pruning-experiments/dcaecore/train_dc_ae.py\", line 245, in main\n",
            "    trainer.train()\n",
            "  File \"/content/model-pruning-experiments/dcaecore/trainer.py\", line 226, in train\n",
            "    val_info = self.validate(epoch=epoch)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/efficientvit/apps/trainer/base.py\", line 171, in validate\n",
            "    return self._validate(model, data_loader, epoch)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/model-pruning-experiments/dcaecore/trainer.py\", line 129, in _validate\n",
            "    \"val/reconstructions\": [wandb.Image(sample_path) for sample_path in os.listdir(sample_dir)]\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/model-pruning-experiments/dcaecore/trainer.py\", line 129, in <listcomp>\n",
            "    \"val/reconstructions\": [wandb.Image(sample_path) for sample_path in os.listdir(sample_dir)]\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py\", line 177, in __init__\n",
            "    self._initialize_from_path(data_or_path)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py\", line 275, in _initialize_from_path\n",
            "    self._set_file(path, is_tmp=False)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/base_types/media.py\", line 131, in _set_file\n",
            "    with open(self._path, \"rb\") as f:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'sample_0.png'\n",
            "[rank0]: Traceback (most recent call last):\n",
            "[rank0]:   File \"/content/model-pruning-experiments/dcaecore/train_dc_ae.py\", line 253, in <module>\n",
            "[rank0]:     main()\n",
            "[rank0]:   File \"/content/model-pruning-experiments/dcaecore/train_dc_ae.py\", line 245, in main\n",
            "[rank0]:     trainer.train()\n",
            "[rank0]:   File \"/content/model-pruning-experiments/dcaecore/trainer.py\", line 226, in train\n",
            "[rank0]:     val_info = self.validate(epoch=epoch)\n",
            "[rank0]:                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/efficientvit/apps/trainer/base.py\", line 171, in validate\n",
            "[rank0]:     return self._validate(model, data_loader, epoch)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/content/model-pruning-experiments/dcaecore/trainer.py\", line 129, in _validate\n",
            "[rank0]:     \"val/reconstructions\": [wandb.Image(sample_path) for sample_path in os.listdir(sample_dir)]\n",
            "[rank0]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/content/model-pruning-experiments/dcaecore/trainer.py\", line 129, in <listcomp>\n",
            "[rank0]:     \"val/reconstructions\": [wandb.Image(sample_path) for sample_path in os.listdir(sample_dir)]\n",
            "[rank0]:                             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py\", line 177, in __init__\n",
            "[rank0]:     self._initialize_from_path(data_or_path)\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py\", line 275, in _initialize_from_path\n",
            "[rank0]:     self._set_file(path, is_tmp=False)\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/base_types/media.py\", line 131, in _set_file\n",
            "[rank0]:     with open(self._path, \"rb\") as f:\n",
            "[rank0]:          ^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]: FileNotFoundError: [Errno 2] No such file or directory: 'sample_0.png'\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mworldly-violet-11\u001b[0m at: \u001b[34mhttps://wandb.ai/tahaa/dcae-finetuning/runs/aibsj2dv\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250213_090026-aibsj2dv/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_gF80yz-wyd"
      },
      "source": [
        "## View Results\n",
        "\n",
        "The results are saved in the `output` directory:\n",
        "- Pruning analysis reports\n",
        "- Reconstructed images\n",
        "- Model statistics"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}